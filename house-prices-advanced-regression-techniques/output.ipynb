{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1\n",
    "train=pd.read_csv(\"./train.csv\")\n",
    "test=pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 3\n",
    "train=pd.read_csv(\"./train.csv\")\n",
    "test=pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 4\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 5\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 6\n",
    "xtest=test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 7\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 8\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 9\n",
    "#Salesprice is skewed to the right\n",
    "ytrain.hist(bins=50)\n",
    "plt.xlabel('SalePrice',fontsize=12)\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.title('SalePrice Histogram')\n",
    "ytrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 10\n",
    "#Salesprice is skewed to the right\n",
    "train.hist(bins=50)\n",
    "plt.xlabel('SalePrice',fontsize=12)\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.title('SalePrice Histogram')\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 11\n",
    "train.head()\n",
    "ytrain=train['SalePrice']\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 12\n",
    "ytrain=train['SalePrice']\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 13\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 14\n",
    "#Salesprice is skewed to the right\n",
    "ytrain.hist(bins=50)\n",
    "plt.xlabel('SalePrice',fontsize=12)\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.title('SalePrice Histogram')\n",
    "ytrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 15\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "mask = np.zeros_like(train.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train.corr(),vmin=.2,square=True,mask=mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 16\n",
    "s=train.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "corr=pd.DataFrame(s)\n",
    "corr=corr.rename(columns={0: 'abs(r)'})\n",
    "corr[corr['abs(r)']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 17\n",
    "corrdf=train.corr()\n",
    "topscorr=pd.DataFrame(corrdf[corrdf['SalePrice']>0.50]['SalePrice'].abs().sort_values(ascending=False))\n",
    "mask = np.zeros_like(train[topscorr.index].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train[topscorr.index].corr(),square=True,annot=True, mask=mask, fmt='.2f',annot_kws={'size': 10},vmin=.2)\n",
    "topscorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 18\n",
    "#top correlated variables with respect to salesprice\n",
    "corrdf=train.corr()\n",
    "topscorr=pd.DataFrame(corrdf[corrdf['SalePrice']>0.50]['SalePrice'].abs().sort_values(ascending=False))\n",
    "mask = np.zeros_like(train[topscorr.index].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train[topscorr.index].corr(),square=True,annot=True, mask=mask, fmt='.2f',annot_kws={'size': 10},vmin=.2)\n",
    "topscorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 19\n",
    "#About the highest R value OverallQual\n",
    "# this is an ordinal categorical variable represented by integers\n",
    "np.sort(train.OverallQual.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 20\n",
    "#Boxplots to show trends of Saleprice vs Overall Qual\n",
    "bplot_data=train[['SalePrice', 'OverallQual']]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=bplot_data)\n",
    "plt.xlabel('OverallQual',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)\n",
    "plt.title('Boxplots of Overall Qual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 21\n",
    "#Continuous variable\n",
    "train.GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 22\n",
    "#There are two outliers GrLvArea>4000, but generally there is a linear relationship\n",
    "GrLiv_data=train[['SalePrice', 'GrLivArea']]\n",
    "GrLiv_data.plot.scatter(x='GrLivArea', y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel('GrLivArea',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 23\n",
    "#Possible candidates for outliers\n",
    "train[(GrLiv_data['GrLivArea']>4000) & (GrLiv_data['SalePrice']<200000) ][['GrLivArea','OverallQual','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 24\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 25\n",
    "print(misval.shape[0],\" total missing values\" )\n",
    "print((misval['misval_train']!=0).sum(), \"missing values in training set\")\n",
    "print((misval['misval_test']!=0).sum(), \"missing values in test set\")\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 26\n",
    "get_ipython().system('grep -B8 NA data_description.txt')\n",
    "#14 with NA in description 5 basement qual 4 garage qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 27\n",
    "# impute NA to category NA\n",
    "cols= ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MiscFeature'].unique(),xtest['MiscFeature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 28\n",
    "#NA and 0's match there are no NAs that are missing values!\n",
    "print(xtest[(xtest['Fireplaces']==0) & (xtest['FireplaceQu']!='NA')].shape[0],\n",
    "      train[(train['Fireplaces']==0) & (train['FireplaceQu']!='NA')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 29\n",
    "#Three missing values for Poolarea\n",
    "print(xtest[(xtest['PoolQC']=='NA') & (xtest['PoolArea']>0)].shape[0],\n",
    "train[(train['PoolQC']=='NA') & (train['PoolArea']>0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[(xtest['PoolQC']== 'NA') & (xtest['PoolArea']>0)][['OverallQual', 'PoolQC', 'PoolArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 30\n",
    "fig = sns.catplot(y='OverallQual', x=\"PoolQC\",order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)\n",
    "fig1 = sns.catplot(x='PoolQC', y=\"PoolArea\", order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 31\n",
    "#slight increase in quality vs pool qc-- give FA for all missing data\n",
    "xtest['PoolQC']=xtest['PoolQC'].replace({'NA':'Fa'})\n",
    "print(xtest[(xtest['PoolQC']=='NA') & (xtest['PoolArea']>0)].shape[0],\n",
    "train[(train['PoolQC']=='NA') & (train['PoolArea']>0)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 32\n",
    "# Training set: 81 entries with no garage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond']\n",
    "print(train.filter(regex='Garage').isna().sum())\n",
    "print('total number of entries with misvals is',\n",
    "      pd.isnull(train[cols].any(axis=1)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 33\n",
    "#Double check to make sure that all entries with no garage have zero values for \n",
    "#garagecars and garage area\n",
    "train[pd.isnull(train['GarageType'])][['GarageCars','GarageArea']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 34\n",
    "print(xtest.filter(regex='Garage').isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at all the entries with missing garagetype, check if the other entries are zero or NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtest[pd.isnull(xtest['GarageType'])][cols].notna().sum().sum(), \n",
    "xtest[pd.isnull(xtest['GarageType'])][['GarageCars','GarageArea']].sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76 entries confirmed with no garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#This confirms that there may be 2 entries with missval\n",
    "print(xtest[pd.isnull(xtest['GarageYrBlt'])][cols].notna().sum())\n",
    "print('The two potential misvals occur at',xtest[pd.isnull(xtest['GarageYrBlt'])]['GarageType'].notna().nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[pd.isnull(xtest['GarageYrBlt'])].filter(regex='Garage').iloc[[33, 55]]\n",
    "#xtest.iloc[[666,1116]].fillna('NANA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 35\n",
    "cols= ['GarageYrBlt','GarageFinish','GarageQual','GarageCond','GarageCars','GarageArea']\n",
    "for i in range(len(cols)):\n",
    "    scale_mapper = {np.nan: train[cols[i]].mode()[0]} \n",
    "    xtest[cols[i]].loc[[666,1116]]=xtest[cols[i]].replace(scale_mapper)\n",
    "    print(train[cols[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 36\n",
    "#Cannot use 0 for area! use 440 as the next most common value.\n",
    "print(train['GarageArea'].value_counts())\n",
    "xtest.loc[1116,'GarageArea']=440\n",
    "xtest.loc[[666,1116]].filter(regex='Garage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 37\n",
    "Need to remove all NA's before running imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['GarageType','GarageFinish','GarageQual','GarageCond','GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[cols].isna().sum().sum(),xtest[cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 38\n",
    "cols=train.filter(regex='Bsmt').loc[:, train.filter(regex='Bsmt').isnull().any()].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 39\n",
    "print(train.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in training set with misvals is',\n",
    "      pd.isnull(train.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total of 39 entries, there is 37 common entries that have missing values across\n",
    "and there are two unique entries that have misvals in exposure and type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 40\n",
    "train[pd.isnull(train[cols]).any(axis=1)].filter(regex='Bsmt').loc[[332,948]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 41\n",
    "#Impute 332 to Rec, it is not unfinished because all 3 bsmtfinSF >0\n",
    "print(train['BsmtFinType2'].value_counts())\n",
    "#Impute 948 to No\n",
    "print(train['BsmtExposure'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[332,'BsmtFinType2']='Rec'\n",
    "train.loc[948,'BsmtExposure']='No'\n",
    "train.loc[[332,948]].filter(regex='Bsmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 42\n",
    "print(xtest.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in test set with misvals is',\n",
    "      pd.isnull(xtest.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Fix the the NA values that are clearly meant to be 0\n",
    "cols1=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']\n",
    "temp[temp[cols].isnull().all(axis=1)].loc[[660,728]]\n",
    "xtest.loc[[660,728],cols1]=0\n",
    "xtest.loc[[660,728],cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 43\n",
    "print(xtest.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in test set with misvals is',\n",
    "      pd.isnull(xtest.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Fix the the NA values that are clearly meant to be 0\n",
    "cols1=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']\n",
    "#temp[temp[cols].isnull().all(axis=1)].loc[[660,728]]\n",
    "xtest.loc[[660,728],cols1]=0\n",
    "xtest.loc[[660,728],cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 44\n",
    "#And then impute the Missing values for the 7 other values\n",
    "temp=xtest[pd.isnull(xtest[cols]).any(axis=1)].filter(regex='Bsmt')\n",
    "cols=['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']\n",
    "temp[~temp[cols].isnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 45\n",
    "print(xtest.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in test set with misvals is',\n",
    "      pd.isnull(xtest.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Fix the the NA values that are clearly meant to be 0\n",
    "cols1=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']\n",
    "temp[temp[cols].isnull().all(axis=1)].loc[[660,728]]\n",
    "xtest.loc[[660,728],cols1]=0\n",
    "xtest.loc[[660,728],cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 46\n",
    "#Impute missing values for the 7 entries\n",
    "cols= ['BsmtQual','BsmtCond','BsmtExposure']\n",
    "ind=temp[~temp[cols].isnull().all(axis=1)].index\n",
    "for i in range(len(cols)):\n",
    "    scale_mapper = {np.nan: train[cols[i]].value_counts().keys()[0]} \n",
    "    xtest[cols[i]].loc[ind]=xtest[cols[i]].replace(scale_mapper)\n",
    "    print(train[cols[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if it worked    \n",
    "xtest[cols].loc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 47\n",
    "#Fill in the NA values\n",
    "cols=xtest.filter(regex='Bsmt').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')\n",
    "#Check to see that there are no NA values\n",
    "(train[cols].isna().sum().sum(),xtest[cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 48\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 49\n",
    "Will run simple imputation of mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage'].hist()\n",
    "plt.title('LotFrontage');\n",
    "plt.ylabel('Counts');\n",
    "plt.xlabel('LotFrontage')\n",
    "LF_mode=xtrain['LotFrontage'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage']=train['LotFrontage'].fillna(LF_mode)\n",
    "xtest['LotFrontage']=xtest['LotFrontage'].fillna(LF_mode)\n",
    "# A second Pass could entail looking at lot variables, street variables, to learn regression for lot frontage\n",
    "#plt.scatter(x='LotArea', y='LotFrontage', data=train);\n",
    "#axes = plt.axes()\n",
    "#axes.set_xlim([0, 100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 50\n",
    "Will run simple imputation of mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage'].hist()\n",
    "plt.title('LotFrontage');\n",
    "plt.ylabel('Counts');\n",
    "plt.xlabel('LotFrontage')\n",
    "LF_mode=train['LotFrontage'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage']=train['LotFrontage'].fillna(LF_mode)\n",
    "xtest['LotFrontage']=xtest['LotFrontage'].fillna(LF_mode)\n",
    "# A second Pass could entail looking at lot variables, street variables, to learn regression for lot frontage\n",
    "#plt.scatter(x='LotArea', y='LotFrontage', data=train);\n",
    "#axes = plt.axes()\n",
    "#axes.set_xlim([0, 100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 51\n",
    "cols=['MasVnrArea','MasVnrType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[(train['MasVnrArea']<20) & (train['MasVnrArea']>0)][cols]\n",
    "xtest[(xtest['MasVnrArea']<20) & (xtest['MasVnrArea']>0)][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume that the MasVnrArea of 1 is actually meant to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 52\n",
    "#Lets assume MassVnrtype is None for the two cases where MasVnrArea=0\n",
    "train[(train['MasVnrArea']==0) &(train['MasVnrType']!='None')][cols]\n",
    "xtest[(xtest['MasVnrArea']==0) &(xtest['MasVnrType']!='None')][cols]\n",
    "train.loc[[688,1241],cols[1]]= 'None'\n",
    "xtest.loc[[859],cols[1]]= 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets also assume that all NA's are 'None and zero'\n",
    "train[train[cols].isnull().all(axis=1)][cols]\n",
    "xtest[xtest[cols].isnull().all(axis=1)][cols]\n",
    "train[cols[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols[0]]=train[cols[0]].fillna(0)\n",
    "xtest[cols[0]]=xtest[cols[0]].fillna(0)\n",
    "train[cols[1]]=train[cols[1]].fillna('None')\n",
    "xtest[cols[1]]=xtest[cols[1]].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 53\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 54\n",
    "cols=misval.index.tolist()\n",
    "for i in range(len(cols)):\n",
    "    #print(xtest[cols[i]].fillna(xtest[cols[i]].value_counts()[0]))\n",
    "    xtest[cols[i]]=xtest[cols[i]].fillna(train[cols[i]].value_counts().keys()[0])\n",
    "    train[cols[i]]=train[cols[i]].fillna(train[cols[i]].value_counts().keys()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 55\n",
    "# NO missing Values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 56\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 57\n",
    "import re\n",
    "file=open('./categorical.txt','r')\n",
    "stringlist=file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 58\n",
    "dictlist=[]\n",
    "for i in range(len(stringlist)):\n",
    "    value=[]\n",
    "    if re.match('^\\S', stringlist[i]):\n",
    "        key=stringlist[i]\n",
    "        n=i\n",
    "        for j in range(len(stringlist[n+1:])):\n",
    "            if re.match('^\\s',stringlist[n+1:][j]):\n",
    "                value.append(stringlist[n+1:][j].split(maxsplit=1)[0])                \n",
    "            elif re.match('^\\S',stringlist[n+1:][j]):\n",
    "                break       \n",
    "        dictlist.append({key: value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 59\n",
    "dictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 60\n",
    "dictlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 61\n",
    "# dictlist.pop(0), dictlist.pop(13) remove all the numerical values\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 62\n",
    "stringlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 63\n",
    "stringlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 64\n",
    "stringlist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 65\n",
    "dictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 66\n",
    "dictlist={}\n",
    "for i in range(len(stringlist)):\n",
    "    value=[]\n",
    "    #if there is no spaces in the line entry, add as key\n",
    "    if re.match('^\\S', stringlist[i]):\n",
    "        key=stringlist[i]\n",
    "        n=i\n",
    "        #add all entries that have a space as a value \n",
    "        for j in range(len(stringlist[n+1:])):\n",
    "            if re.match('^\\s',stringlist[n+1:][j]):\n",
    "                value.append(stringlist[n+1:][j].split(maxsplit=1)[0])  \n",
    "        #break until the next key is observed\n",
    "            elif re.match('^\\S',stringlist[n+1:][j]):\n",
    "                break       \n",
    "        dictlist.append({key: value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 67\n",
    "dictlist=[]\n",
    "for i in range(len(stringlist)):\n",
    "    value=[]\n",
    "    #if there is no spaces in the line entry, add as key\n",
    "    if re.match('^\\S', stringlist[i]):\n",
    "        key=stringlist[i]\n",
    "        n=i\n",
    "        #add all entries that have a space as a value \n",
    "        for j in range(len(stringlist[n+1:])):\n",
    "            if re.match('^\\s',stringlist[n+1:][j]):\n",
    "                value.append(stringlist[n+1:][j].split(maxsplit=1)[0])  \n",
    "        #break until the next key is observed\n",
    "            elif re.match('^\\S',stringlist[n+1:][j]):\n",
    "                break       \n",
    "        dictlist.append({key: value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 68\n",
    "dictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 69\n",
    "dictlist[0].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 70\n",
    "dictlist[0].keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 71\n",
    "dictlist[0].keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 72\n",
    "dictlist[0].keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 73\n",
    "dictlist[0].keys(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 74\n",
    "dictlist[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 75\n",
    "dictlist[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 76\n",
    "dictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 77\n",
    "dictlist(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 78\n",
    "dictlist[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 79\n",
    "dictlist[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 80\n",
    "dictlist[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 81\n",
    "dictlist.pop(0)#, dictlist.pop(13) remove all the numerical values\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 82\n",
    "dictlist[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 83\n",
    "dictlist.pop(14)#, dictlist.pop(13) remove all the numerical values\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 84\n",
    "dictlist[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 85\n",
    "dictlist[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 86\n",
    "dictlist.pop(13)#, dictlist.pop(13) remove all the numerical values\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 87\n",
    "dictlist[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 88\n",
    "dictlist[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 89\n",
    "dictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 90\n",
    "for i in range(len(dictlist)):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value)}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    train[key]=train[key].replace(scale_mapper)\n",
    "    xtest[key]=xtest[key].replace(scale_mapper)\n",
    "#train[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 91\n",
    "# = pd.Series(['A', 'B', 'Aaba', 'Baca', np.nan, 'CABA', 'cat'])\n",
    "train.str.contains('\\S', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 92\n",
    "fig = sns.boxplot(y='SalePrice', x=\"MSSubClass\", data=train)\n",
    "#MSsubclass is not ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 93\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 94\n",
    "train.info()==object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 95\n",
    "select_dtypes(exclude=['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 96\n",
    "train.select_dtypes(exclude=['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 97\n",
    "train.select_dtypes(exclude=['int','float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 98\n",
    "train.select_dtypes(exclude=['int','float']).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 99\n",
    "train.select_dtypes(exclude=['int64','float']).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 100\n",
    "train.select_dtypes(exclude=['int64','float']).info()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 101\n",
    "train.select_dtypes(exclude=['int64','float']).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 102\n",
    "train.select_dtypes(exclude=['int64','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 103\n",
    "train.select_dtypes(exclude=['int64','float']).columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 104\n",
    "train.select_dtypes(exclude=['int64','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 105\n",
    "train.select_dtypes(exclude=['int64','float']).columns.aslist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 106\n",
    "train.select_dtypes(exclude=['int64','float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 107\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 108\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 109\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 110\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 111\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 112\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[0]].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 113\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[0]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 114\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[1]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 115\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[2]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 116\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[3]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 117\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[4]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 118\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[5]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 119\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[6]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 120\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[7]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 121\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[8]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 122\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[9]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 123\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[10]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 124\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[0]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 125\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[9]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 126\n",
    "error_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 127\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "train[error_cols[8]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 128\n",
    "#Test to make sure that that the encoding worked\n",
    "temp=pd.read_csv(\"./train.csv\")\n",
    "x='Functional'\n",
    "temp[x].value_counts(),train[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 129\n",
    "train[error_cols[8]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 130\n",
    "train[error_cols[8]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 131\n",
    "train[error_cols[8]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 132\n",
    "train[error_cols[8]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 133\n",
    "train[error_cols[8]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 134\n",
    "train[error_cols[8]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 135\n",
    "train[error_cols[7]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 136\n",
    "train[error_cols[6]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 137\n",
    "train[error_cols[5]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 138\n",
    "train[error_cols[4]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 139\n",
    "train[error_cols[3]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 140\n",
    "train[error_cols[2]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 141\n",
    "train[error_cols[1]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood 'NAmes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 142\n",
    "train[error_cols[0]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood 'NAmes'\n",
    "#KitchenQual has in values but shows dtype of object for some reaso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 143\n",
    "train[error_cols[0]].unique()[3]\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 144\n",
    "train[error_cols[0]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 145\n",
    "train[error_cols[0]].unique()[1]\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 146\n",
    "train[error_cols[0]].unique()[2]\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 147\n",
    "train[error_cols[1]]\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 148\n",
    "train[error_cols[1]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 149\n",
    "train[error_cols[2]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 150\n",
    "train[error_cols[2]].value_counts()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 151\n",
    "train[error_cols[3]].value_counts()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 152\n",
    "train[error_cols[4]].value_counts()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 153\n",
    "train[error_cols[0]].value_counts()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 154\n",
    "train[error_cols[1]].value_counts()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 155\n",
    "train[error_cols[1]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 156\n",
    "train[error_cols[2]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 157\n",
    "train[error_cols[3]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 158\n",
    "train[error_cols[3]].value_counts()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 159\n",
    "train[error_cols[4]].value_counts()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 160\n",
    "train[error_cols[4]].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 161\n",
    "x=error_cols[4]\n",
    "train[x].unique()\n",
    "#GarageYrBlt has instances of NA---FIX\n",
    "#Functional has int values but shows dytpe of object for some reason\n",
    "#KitchenQual has in values but shows dtype of object for some reason\n",
    "#ExterQual \"\"\n",
    "#Exter2nd(5) has uncoverted instances\n",
    "#Exter1st has uncoverted instances\n",
    "#'Bldgtype' \"\"\n",
    "#Neighborhood \"\" 'NAmes'\n",
    "#MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'Wd Sdng': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 162\n",
    "x=error_cols[0]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 163\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'C (all)': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 164\n",
    "x=error_cols[1]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 165\n",
    "x=error_cols[2]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 166\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NAmes': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 167\n",
    "x=error_cols[3]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 168\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'2fmCon': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 169\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'Duplex': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 170\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'Twnhs': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 171\n",
    "x=error_cols[4]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 172\n",
    "x=error_cols[5]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 173\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'CmentBd': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 174\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'Wd Sdng': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 175\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'Wd Shng': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 176\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'Brk Cmn': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 177\n",
    "x=error_cols[6]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 178\n",
    "x=error_cols[7]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 179\n",
    "x=error_cols[8]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 180\n",
    "x=error_cols[9]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 181\n",
    "#Test to make sure that that the encoding worked\n",
    "temp=pd.read_csv(\"./train.csv\")\n",
    "x='Functional'\n",
    "temp[x].value_counts(),train[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 182\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 183\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 184\n",
    "train['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 185\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 186\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 187\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 188\n",
    "train.select_dtypes(exclude=['int64','float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 189\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 190\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=err_cols[0]\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 191\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 192\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[x].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 193\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 194\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[1]\n",
    "train[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 195\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[2]\n",
    "train[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 196\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[2]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 197\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[1]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 198\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 199\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[1]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 200\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[2]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 201\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[3]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 202\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[4]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 203\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[5]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 204\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[4]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 205\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[3]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 206\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[2]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 207\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[1]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 208\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[2]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 209\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[3]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 210\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 211\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[0]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 212\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[1]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 213\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[2]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 214\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[3]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 215\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[4]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 216\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[5]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 217\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[6]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 218\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[7]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 219\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[0]\n",
    "train[train.columns[8]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 220\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 221\n",
    "xtest['Electrical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 222\n",
    "xtest['Electrical'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 223\n",
    "xtest['Electrical'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 224\n",
    "xtest['Electrical'].unique()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 225\n",
    "type(xtest['Electrical'].unique()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 226\n",
    "type(xtest['Electrical'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 227\n",
    "type(xtest['Electrical'].unique()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 228\n",
    "type(xtest['Electrical'].unique()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 229\n",
    "type(xtest['Electrical'].unique()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 230\n",
    "type(xtest['Electrical'].unique()[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 231\n",
    "type(xtest['Electrical'].unique()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 232\n",
    "xtest['Electrical'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 233\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 234\n",
    "xtest['ExterQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 235\n",
    "xtest['PoolQc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 236\n",
    "xtest['PoolQC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 237\n",
    "xtest['Functional'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 238\n",
    "xtest['Condition2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 239\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain[xtrain['MSZoning']=='C (all)']['MSZoning'][30] #.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 240\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 241\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 242\n",
    "xtrain['YearBuilt'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 243\n",
    "xtrain['RemodAdd'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 244\n",
    "xtrain['YearRemodAdd'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 245\n",
    "xtrain['YearRemodAdd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 246\n",
    "xtrain['YearRemodAdd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 247\n",
    "GrLiv_data=train[['SalePrice', 'YearRemodAdd']]\n",
    "GrLiv_data.plot.scatter(x='YearRemodAdd', y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel('YearRemodAdd',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 248\n",
    "GrLiv_data=train[['SalePrice', 'YearRemodAdd']]\n",
    "GrLiv_data.plot.scatter(x='YearRemodAdd', y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel('YearBuilt',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 249\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 250\n",
    "x='GarageYrBlt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 251\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 252\n",
    "train[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 253\n",
    "x='YrSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 254\n",
    "train[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 255\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 256\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 257\n",
    "x='YrSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 258\n",
    "x='GarageYrBlt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 259\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 260\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 261\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 262\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 263\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 264\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 265\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 266\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 267\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 268\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 269\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 270\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 271\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 272\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 273\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 274\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 275\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 276\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 277\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 278\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True,[1,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 279\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True,[1,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 280\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,retbins=True,bins=[1,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 281\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,bins=[1,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 282\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]),bins=[1,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 283\n",
    "pd.cut(np.array([1, 7, 5, 4, 6, 3]),bins=[1,2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 284\n",
    "pd.cut(train[x], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 285\n",
    "pd.cut(train[x], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 286\n",
    "pd.cut(train[x], 5,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 287\n",
    "x='YrSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 288\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 289\n",
    "pd.cut(train[x], 7,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 290\n",
    "pd.cut(train[x], 8,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 291\n",
    "pd.cut(train[x], 10,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 292\n",
    "pd.cut(train[x], 12,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 293\n",
    "pd.cut(train[x], 13,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 294\n",
    "pd.cut(train[x], 14,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 295\n",
    "bins=[1870,1920,1960,1970,1980,1990,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 296\n",
    "pd.cut(train[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 297\n",
    "pd.cut(train[x],bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 298\n",
    "pd.cut(train[x],bins).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 299\n",
    "bins=[1870,1920,1960,1970,1980,1990,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 300\n",
    "bins=[1870,1920,1960,1970,1980,1990,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 301\n",
    "bins=[1870,1920,1960,1970,1980,1990,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 302\n",
    "bins=[1870,1920,1960,1970,1980,1990,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 303\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 304\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {(1920, 1960]  : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 305\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'(1920, 1960]'  : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 306\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 307\n",
    "x.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 308\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 309\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 310\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 311\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 312\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'(1920, 1960]'  : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "#xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 313\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {(1920, 1960]  : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "#xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 314\n",
    "arf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 315\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 316\n",
    "arf.value_counts()[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 317\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 318\n",
    "arf.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 319\n",
    "arf.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 320\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 321\n",
    "arf.value_counts().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 322\n",
    "arf.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 323\n",
    "arf.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 324\n",
    "arf.unique()[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 325\n",
    "arf.unique()[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 326\n",
    "arf.unique()[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 327\n",
    "arf.unique()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 328\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "#xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 329\n",
    "len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 330\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=len(bins)-1)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "#xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 331\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=len(bins)-1)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "#xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 332\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=len(bins)-1)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 333\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=7)\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 334\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6,7])\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 335\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6])\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 336\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6])\n",
    "arf.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper= {(arf.unique()[6]  : 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arf[x]=arf[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 337\n",
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6])\n",
    "arf.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=arf\n",
    "#xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 338\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 339\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 340\n",
    "train[x].astype(int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 341\n",
    "train[x].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 342\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 343\n",
    "train[x]=train[x].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 344\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 345\n",
    "train[x]=train[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 346\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 347\n",
    "x='Mosold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 348\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 349\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],4,labels=[0,1,2,3])\n",
    "arf\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 350\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],4)\n",
    "arf\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 351\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[1,2,3,4]\n",
    "arf=pd.cut(train[x],bins,labels=bins)\n",
    "arf\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 352\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[0,1,2,3,4]\n",
    "arf=pd.cut(train[x],bins,labels=bins)\n",
    "arf\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 353\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[0,1,2,3,4]\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 354\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 355\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins)\n",
    "arf\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 356\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3])\n",
    "arf\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 357\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3])\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 358\n",
    "#Bin Months\n",
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3])\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 359\n",
    "#Bin Months\n",
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3])\n",
    "train[x]=arf.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 360\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 361\n",
    "#Bin Months\n",
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3])\n",
    "#train[x]=arf.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 362\n",
    "temp=pd.read_csv(\"./train.csv\")\n",
    "temp['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 363\n",
    "temp=pd.read_csv(\"./train.csv\")\n",
    "temp['MoSold']=train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 364\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 365\n",
    "tempsold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 366\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 367\n",
    "temp['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 368\n",
    "temp['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 369\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 370\n",
    "temp['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 371\n",
    "r['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 372\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "#train[x]=temp['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 373\n",
    "r['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 374\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 375\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 376\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 377\n",
    "#Bin Months\n",
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3])\n",
    "#train[x]=arf.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 378\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 379\n",
    "arf.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 380\n",
    "arf.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 381\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 382\n",
    "arf.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 383\n",
    "#Bin Months\n",
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "#train[x]=arf.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 384\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 385\n",
    "#Bin Months\n",
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 386\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 387\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 388\n",
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "x='YearBuilt'\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6])\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 389\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 390\n",
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "x='YearBuilt'\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 391\n",
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 392\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['YearBuilt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 393\n",
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "x='YearBuilt'\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 394\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 395\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 396\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 397\n",
    "train[x]==12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 398\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 399\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 400\n",
    "train[x]==12\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 401\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 402\n",
    "Bin Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 403\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 404\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 405\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 406\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 407\n",
    "train[x]==12\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 408\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 409\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 410\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 411\n",
    "train[x]==12\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 412\n",
    "r=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r['MoSold']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 413\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 414\n",
    "train[x]==12\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 415\n",
    "train[x]==12\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 416\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 417\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[0,3,6,9,12]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 418\n",
    "arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 419\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "#train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 420\n",
    "arf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 421\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 422\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 423\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 424\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 425\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 426\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['MoSold']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 427\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 428\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 429\n",
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 430\n",
    "x='MoSold'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 431\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 432\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 433\n",
    "data=test[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 434\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 435\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 436\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['YearBuilt']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 437\n",
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "x='YearBuilt'\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "train[x]=arf\n",
    "xtext[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 438\n",
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "x='YearBuilt'\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 439\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['YearBuilt']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 440\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "train[x]=r['YearBuilt']\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 441\n",
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "x='YearBuilt'\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 442\n",
    "xtest[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 443\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 444\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 445\n",
    "#Make sure that we are correctly binning everytime this cell is run\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "x='YearBuilt'\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 446\n",
    "xtest[x].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 447\n",
    "xtest[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 448\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 449\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 450\n",
    "x='MoSold'\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 451\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 452\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 453\n",
    "#Make sure that we are correctly binning everytime this cell is run\n",
    "x='YearBuilt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin Years built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[1870,1920,1960,1970,1980,1990,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='YearBuilt'\n",
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 454\n",
    "x='MoSold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 455\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 456\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 457\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 458\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]\n",
    "train['YearBuilt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 459\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 460\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 461\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 462\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 463\n",
    "x='YrSold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 464\n",
    "x.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 465\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 466\n",
    "x='YrSold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {2006: 0,2007:1,2008:2,2009:3 2010:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 467\n",
    "x='YrSold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {2006: 0,2007:1,2008:2,2009:3, 2010:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 468\n",
    "x='YearBuilt'\n",
    "train(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 469\n",
    "x='YearBuilt'\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 470\n",
    "x='YearBuilt'\n",
    "train[x],xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 471\n",
    "x='YearBuilt'\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 472\n",
    "x='YearBuilt'\n",
    "xtest[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 473\n",
    "x='YearRemodAdd'\n",
    "xtest[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 474\n",
    "x='YearRemodAdd'\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 475\n",
    "x='YearRemodAdd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 476\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]\n",
    "labels=[0,1,2,3,4,5,6]\n",
    "arf=pd.cut(train[x],bins).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 477\n",
    "train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 478\n",
    "train(x).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 479\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 480\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]\n",
    "labels=[0,1,2,3,4,5,6]\n",
    "arf=pd.cut(train[x],bins,labels).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 481\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]\n",
    "labels=[0,1,2,3,4,5,6]\n",
    "arf=pd.cut(train[x],bins,labels) #.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 482\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 483\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]\n",
    "labels=[0,1,2,3,4,5]\n",
    "arf=pd.cut(train[x],bins,labels) #.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 484\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 485\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5]) #.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 486\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 487\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5]) #.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 488\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]\n",
    "labels=[0,1,2,3,4,5]\n",
    "arf=pd.cut(train[x],bins,labels).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 489\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]\n",
    "labels=[0,1,2,3,4,5]\n",
    "arf=pd.cut(train[x],bins,labels)#.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 490\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 491\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 492\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]\n",
    "labels=[0,1,2,3,4,5]\n",
    "arf=pd.cut(train[x],bins,labels)#.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 493\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 494\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5])#.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 495\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 496\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5]).astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 497\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 498\n",
    "arf=pd.DataFrame()\n",
    "bins=[1950,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 499\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 500\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 501\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 502\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 503\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 504\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 505\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "#train[x]=r[x]\n",
    "#xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "r.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 506\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "#train[x]=r[x]\n",
    "#xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "r[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 507\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "r[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 508\n",
    "Bin Yearemodadd by [1949,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[1949,1960,1970,1980,1990,2000,2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 509\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 510\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 511\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 512\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 513\n",
    "fig = sns.catplot(y='SalePrice', x, data=train)\n",
    "#fig1 = sns.catplot(x='PoolQC', y=\"PoolArea\", order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 514\n",
    "fig = sns.catplot(y='SalePrice', x='GarageYrBuilt', data=train)\n",
    "#fig1 = sns.catplot(x='PoolQC', y=\"PoolArea\", order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 515\n",
    "fig = sns.catplot(y='SalePrice', x='GarageYrBlt', data=train)\n",
    "#fig1 = sns.catplot(x='PoolQC', y=\"PoolArea\", order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 516\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp=train[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 517\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 518\n",
    "temp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 519\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 520\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 521\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 522\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(1750,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 523\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(1750,80000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 524\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',xlim=(1750,80000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 525\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1750,80000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 526\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1750,8000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 527\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2010));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 528\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2012));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 529\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2013));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 530\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2014));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 531\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2015));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 532\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2016));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 533\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2017));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 534\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1780,2019));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 535\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1900,2019));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 536\n",
    "temp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 537\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 538\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 539\n",
    "temp['GarageYrBlt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 540\n",
    "temp['GarageYrBlt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 541\n",
    "temp['GarageYrBlt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 542\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1850,2019));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 543\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {'NA': 0}\n",
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1900,2019));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 544\n",
    "bins=[-1,1899,1920,1940,1960,1980,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 545\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 546\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 547\n",
    "train[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 548\n",
    "train[x].replace(scale_mapper).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 549\n",
    "bins=[-1,1899,1920,1940,1960,1980,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 550\n",
    "train[x]=train[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 551\n",
    "bins=[-1,1899,1920,1940,1960,1980,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 552\n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 553\n",
    "#train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 554\n",
    "bins=[-1,1899,1920,1940,1960,1980,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "#arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "#train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 555\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 556\n",
    "xtest[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 557\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 558\n",
    "bins=[-1,1899,1920,1940,1960,1980,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 559\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 560\n",
    "arf.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 561\n",
    "arf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 562\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 563\n",
    "xtest[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 564\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "#train[x]=r[x]\n",
    "#xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "ra[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 565\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "#train[x]=r[x]\n",
    "#xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "ra[x].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 566\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "#train[x]=r[x]\n",
    "#xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "ra[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 567\n",
    "bins=[-1,1899,1920,1940,1960,1980,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]) #.astype('int64')\n",
    "#train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 568\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 569\n",
    "arf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 570\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 571\n",
    "arf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 572\n",
    "type(arf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 573\n",
    "arf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 574\n",
    "arf.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 575\n",
    "arf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 576\n",
    "train[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 577\n",
    "arf.bins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 578\n",
    "arf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 579\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 580\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "#train[x]=r[x]\n",
    "#xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "ra[x]==2207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 581\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "#train[x]=r[x]\n",
    "#xtest[x]=ra[x]\n",
    "#xtest[x]\n",
    "ra[ra[x]==2207][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 582\n",
    "xtest[xtest[x]==2207][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 583\n",
    "xtest[xtest[x]].loc(1132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 584\n",
    "xtest[xtest[x]].loc[1132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 585\n",
    "xtest[xtest[x]].iloc[1132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 586\n",
    "xtest[xtest[x]].loc[1132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 587\n",
    "xtest[xtest[x]].iloc[1132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 588\n",
    "xtest.iloc[1132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 589\n",
    "xtest.iloc[1132][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 590\n",
    "xtest.iloc[1132][x]=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 591\n",
    "xtest.iloc[1132][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 592\n",
    "xtest.iloc[1132][x]==6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 593\n",
    "xtest.iloc[1132][x]=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 594\n",
    "xtest.iloc[1132][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 595\n",
    "xtest.loc[train[x] == -9223372036854775808, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 596\n",
    "xtest.loc[xtest[x] == -9223372036854775808, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 597\n",
    "xtest.loc[xtest[x] == -9223372036854775808, x]=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 598\n",
    "xtest.iloc[1132][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 599\n",
    "bins=[-1,1899,1920,1940,1960,1980,2000,2010]\n",
    "arf=pd.DataFrame()\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3,4,5,6]) #.astype('int64')\n",
    "train[x]=arf\n",
    "#xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3,4,5,6]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 600\n",
    "train[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 601\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 602\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 603\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 604\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].replace(scale_mapper)\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1900,2019));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 605\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 606\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x]\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1900,2019));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 607\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].astype('int64')\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(1900,2019));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 608\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].astype('int64')\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(0,8));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 609\n",
    "train[x]=train[x].astype('int64')\n",
    "train[x].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 610\n",
    "train[x]=train[x].astype('int64')\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 611\n",
    "xtest[x]=xtest[x].astype('int64')\n",
    "xtest[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 612\n",
    "x=\"GarageYrBlt\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "temp['GarageYrBlt']=train[x].astype('int64')\n",
    "temp['SalePrice']=train['SalePrice']\n",
    "data=temp[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(-1,7));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 613\n",
    "x=\"Utilities\"\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(-1,7));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 614\n",
    "train[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 615\n",
    "train[x].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 616\n",
    "train[x].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 617\n",
    "train[x].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 618\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 619\n",
    "train['Id'.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 620\n",
    "train['Id'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 621\n",
    "train.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 622\n",
    "x=\"Utilities\"\n",
    "train[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(-1,7));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 623\n",
    "train.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 624\n",
    "train.types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 625\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 626\n",
    "x=\"Utilities\"\n",
    "train[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "data=train[['SalePrice', x]].astype('int64')\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(-1,7));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 627\n",
    "x=['Utilities','ExterQual','KitchenQual','Functional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 628\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 629\n",
    "x=['Utilities','ExterQual','KitchenQual','Functional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 630\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 631\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 632\n",
    "x=['Utilities','ExterQual','KitchenQual','Functional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[x]=xtest[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 633\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 634\n",
    "x=['Condition2','Electrical','Fence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "xtest[x]=xtest[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 635\n",
    "x=['Condition2','Electrical','Fence','PoolQC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "xtest[x]=xtest[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 636\n",
    "train.info()\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 637\n",
    "x=\"Utilities\"\n",
    "train[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame()    \n",
    "data=train[['SalePrice', x]].astype('int64')\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000),xlim=(-1,7));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 638\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 639\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 640\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 641\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 642\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 643\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 644\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 645\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X,= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "@@ Cell 646\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 647\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 648\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 649\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 650\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 651\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=50, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 652\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 653\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, estimator=10)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 654\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, n_estimator=10)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 655\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, n_estimators=10)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 656\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, n_estimators=10)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 657\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, n_estimators=100\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 658\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 659\n",
    "y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 660\n",
    "pd.DataFrame(y).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 661\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 662\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, n_estimators=1000\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 663\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=40, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 664\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 665\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 666\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 667\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=100, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 668\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 669\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 670\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 671\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 672\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 673\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 674\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=5, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 675\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=10, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 676\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=1, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 677\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 678\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 679\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=5, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 680\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=8, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 681\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 682\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 683\n",
    "y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 684\n",
    "plt.plot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 685\n",
    "plt.scatterplot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 686\n",
    "plt.scatter(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 687\n",
    "plt.scatter(y_test, y_pred)\n",
    "(y_test-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 688\n",
    "plt.scatter(y_test, y_pred)\n",
    "(y_test-y_pred)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 689\n",
    "plt.scatter(y_test, y_pred)\n",
    "(y_test-y_pred)*(y_test-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 690\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 691\n",
    "error=np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 692\n",
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 693\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 694\n",
    "y_test-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 695\n",
    "plt.hist(y_test-y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 696\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=5, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 697\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=4, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 698\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 699\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=2, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 700\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 701\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=5, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 702\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=3, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 703\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=15, min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 704\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=150, min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 705\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 706\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 707\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 708\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 709\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features=None,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 710\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features=sqrt,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 711\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features='sqrt',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 712\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features='sqrt',min_samples_split=3, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 713\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features='sqrt',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 714\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features='sqrt',min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 715\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features='sqrt',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 716\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features='lg2',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 717\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features='log2',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 718\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 719\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=10000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 720\n",
    "error=np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 721\n",
    "error=np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 722\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 723\n",
    "plt.hist(y_test-y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 724\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=10000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 725\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=10000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 726\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=10000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 727\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 728\n",
    "train[1:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 729\n",
    "train[2:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 730\n",
    "train[:,2:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 731\n",
    "train[2:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 732\n",
    "train[2:80,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 733\n",
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 734\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 735\n",
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 736\n",
    "train[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 737\n",
    "ytrain=train['SalePrice']\n",
    "train.columns[1:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 738\n",
    "ytrain=train['SalePrice']\n",
    "train.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 739\n",
    "ytrain=train['SalePrice']\n",
    "train[train.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 740\n",
    "ytrain=train['SalePrice']\n",
    "train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 741\n",
    "ytrain=train['SalePrice']\n",
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 742\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 743\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 744\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=10000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 745\n",
    "y_test,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 746\n",
    "y_test-y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 747\n",
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 748\n",
    "plt.plot(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 749\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 750\n",
    "np.log(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 751\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 752\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 753\n",
    "np.log(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 754\n",
    "2^1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 755\n",
    "2**1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 756\n",
    "10**1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 757\n",
    "e**1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 758\n",
    "exp(1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 759\n",
    "np.exp(1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 760\n",
    "np.exp(1.609)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 761\n",
    "plt.scatter(np.log(y_test),np.log(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 762\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 763\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.log(y_test), np.log(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 764\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 765\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 766\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 767\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 768\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rint('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 769\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 770\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 771\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 20,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 772\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 20,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 773\n",
    "plt.scatter((y_train),(y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 774\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 775\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= auto,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 776\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 777\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 20,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 778\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 779\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=10, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 780\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 781\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 782\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=30, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 783\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=10, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 784\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 785\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=3, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 786\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=3, min_samples_leaf=3, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 787\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=1, min_samples_leaf=2, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 788\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, must reduce noise, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 789\n",
    "regr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 790\n",
    "regr.feature_importances_.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 791\n",
    "regr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 792\n",
    "train.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 793\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=train.columns)\n",
    "feat_importances.nlargest(4).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 794\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 795\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=train.columns)\n",
    "#feat_importances.nlargest(4).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 796\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "#feat_importances.nlargest(4).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 797\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(4).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 798\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 799\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 800\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(50).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 801\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(40).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 802\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(30).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 803\n",
    "feat_importances.nlargest(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 804\n",
    "corrdf=train.corr()\n",
    "topscorr=pd.DataFrame(corrdf[corrdf['SalePrice']>0.50]['SalePrice'].abs().sort_values(ascending=False))\n",
    "mask = np.zeros_like(train[topscorr.index].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train[topscorr.index].corr(),square=True,annot=True, mask=mask, fmt='.2f',annot_kws={'size': 10},vmin=.2)\n",
    "topscorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 805\n",
    "feat_importances.nlargest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 806\n",
    "feat_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 807\n",
    "xtrain.columns.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 808\n",
    "feat_importances.nlargest(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 809\n",
    "feat_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 810\n",
    "feat_importances.nlargest(50)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 811\n",
    "feat_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 812\n",
    "feat_importances.nlargest(50).aslist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 813\n",
    "feat_importances.nlargest(50).as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 814\n",
    "feat_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 815\n",
    "feat_importances.nlargest(50).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 816\n",
    "feat_importances.nlargest(50).index.aslist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 817\n",
    "feat_importances.nlargest(50).index.as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 818\n",
    "feat_importances.nlargest(50).index.aslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 819\n",
    "feat_importances.nlargest(50).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 820\n",
    "feat_importances.nlargest(50).index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 821\n",
    "feat_importances.nlargest(50).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 822\n",
    "xtrain[feat_importances.nlargest(50).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 823\n",
    "topcols=feat_importances.nlargest(50).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 824\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain[topcols], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 825\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 826\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 827\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 828\n",
    "topcols=feat_importances.nlargest(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 829\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 830\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 831\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 832\n",
    "topcols=feat_importances.nlargest(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 833\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 834\n",
    "topcols=feat_importances.nlargest(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 835\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 'auto',min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 836\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 3,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 837\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 838\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 839\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 840\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 841\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 842\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "#topcols=feat_importances.nlargest(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 843\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 844\n",
    "regr.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 845\n",
    "Try random forest and see results. One hot encode other values for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, hyper parameter tuning leads to the following at best\n",
    "remove features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 846\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 847\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 848\n",
    "plt.scatter(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 849\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 850\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.log(y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.log(y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 851\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 852\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 853\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], np.log(1+ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 854\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 855\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 856\n",
    "np.exp(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 857\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 858\n",
    "np.exp(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 859\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 860\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 861\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 862\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 863\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 864\n",
    "#Try random forest and see results. One hot encode other values for regression\n",
    "ytrain=train['SalePrice']\n",
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, hyper parameter tuning leads to the following at best\n",
    "remove features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 865\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 866\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=200)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 867\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain[topcols], np.log(ytrain), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error(np.exp(y_train), np.exp(y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 868\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 869\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 870\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)\n",
    "kf.get_n_splits(X)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 871\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 872\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain[train_index], xtest[test_index]\n",
    "    y_train, y_test = ytrain[train_index], ytest[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 873\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 874\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain[train_index], xtrain[test_index]\n",
    "    y_train, y_test = ytrain[train_index], ytrain[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 875\n",
    "xtrain[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 876\n",
    "xtrain.iloc[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 877\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 878\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores[]\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))\n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 879\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))\n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 880\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))\n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 881\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 882\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 883\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 884\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 885\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 886\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 887\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 888\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 889\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 890\n",
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 891\n",
    "x=[0,1,2,3,5,70000]\n",
    "y=[0,1,2,3,5,70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 892\n",
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 893\n",
    "x=[0,1,2,3,5,700000]\n",
    "y=[0,1,2,3,5,700000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 894\n",
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 895\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 896\n",
    "#Try random forest and see results. One hot encode other values for regression\n",
    "ytrain=train['SalePrice']\n",
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "X,y= make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=20, max_features= 10,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred=regr.predict(X_test)\n",
    "y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For cross validation set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print('For Training set')\n",
    "print('Root mean squared error: %.2f'\n",
    "      % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_train, y_predtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is overfit, hyper parameter tuning leads to the following at best\n",
    "remove features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 897\n",
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 898\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 899\n",
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 900\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 901\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 902\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 903\n",
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 904\n",
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 905\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 906\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 907\n",
    "log(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 908\n",
    "np.log(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 909\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=np.log(ytrain)\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 910\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 911\n",
    "ytrain.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 912\n",
    "np.log(ytrain).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 913\n",
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 914\n",
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 915\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 916\n",
    "x=[0,1,2,3,5,700000]\n",
    "y=[0,1,2,3,5,700000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 917\n",
    "x=[0,1,2,3,5,700000]\n",
    "y=[0,1,2,3,5,700000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train,y_predtr)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "#plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 918\n",
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 919\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 920\n",
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(xtrain, ytrain)\n",
    "y_pred=regr.predict(xtest)\n",
    "#y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 921\n",
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(xtrain, ytrain)\n",
    "y_pred=regr.predict(xtest)\n",
    "#y_predtr=regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 922\n",
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(xtrain, ytrain)\n",
    "y_pred=regr.predict(xtest)\n",
    "#y_predtr=regr.predict(X_traind\n",
    "Y_pred.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 923\n",
    "y_pred.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 924\n",
    "savetxt('data.csv', y_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 925\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 926\n",
    "from numpy import savetxt\n",
    "savetxt('data.csv', y_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 927\n",
    "po=pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 928\n",
    "po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 929\n",
    "po[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 930\n",
    "po.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 931\n",
    "po.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 932\n",
    "po.columns[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 933\n",
    "po[po.columns[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 934\n",
    "po[po.columns[0:2]].to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 935\n",
    "po[po.columns[0:2]].to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 936\n",
    "po[po.columns[0:2]].to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 937\n",
    "train.to_csv('train_mod.csv',index=False)\n",
    "xtest.to_csv('test_mod.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 938\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,70000]\n",
    "x=y\n",
    "#plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 939\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=np.array([0,70000])\n",
    "x=y\n",
    "#plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 940\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 941\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 942\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 943\n",
    "x=np.array([0,70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 944\n",
    "x=np.array([0,70000])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 945\n",
    "x=np.array([0,70000])\n",
    "x\n",
    "y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 946\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=np.array([0,70000])\n",
    "y=x\n",
    "#plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 947\n",
    "x=np.array([0,70000])\n",
    "x\n",
    "y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 948\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 949\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 950\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=np.log(ytrain)\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 951\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 952\n",
    "x=np.array([0,700000])\n",
    "x\n",
    "y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 953\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 954\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(ytrain)\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 955\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 956\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 957\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 958\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 959\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 960\n",
    "plt.scatter((y_test),(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 961\n",
    "regr = RandomForestRegressor(max_depth=None, max_features= 5,min_samples_split=2, min_samples_leaf=1, random_state=0, n_estimators=1000)\n",
    "regr.fit(xtrain, ytrain)\n",
    "y_pred=regr.predict(xtest)\n",
    "#y_predtr=regr.predict(X_traind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 962\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 963\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 964\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 965\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 966\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 967\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 968\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 969\n",
    "yltrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 970\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 971\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 972\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 973\n",
    "grid_search.best_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 974\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 975\n",
    "grid_search.best_parameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 976\n",
    "grid_search.best_parameter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 977\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 978\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, scoring=‘neg_mean_squared_error’,param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 979\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, scoring='neg_mean_squared_error',param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 980\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 981\n",
    "grid_search.best_params_\n",
    "#grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 982\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 983\n",
    "grid_search.best_params_\n",
    "#er_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 984\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 985\n",
    "grid_search.best_params_\n",
    "#earch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 986\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=30, max_features= 5,min_samples_split=2, min_samples_leaf=8, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 987\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 988\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=30, max_features= 5,min_samples_split=2, min_samples_leaf=8, random_state=0, n_estimators=1000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 989\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 990\n",
    "trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 991\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 992\n",
    "cvscores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 993\n",
    "np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 994\n",
    "r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 995\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 996\n",
    "r2_score(y_train, y_predtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 997\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 998\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 999\n",
    "x=np.array([0,1])\n",
    "x\n",
    "y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1000\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1001\n",
    "x=np.array([10,15])\n",
    "x\n",
    "y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1002\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1003\n",
    "plt.scatter((y_test),(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1004\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [1,3,8],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1005\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1006\n",
    "grid_search.best_params_\n",
    "#earch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1007\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1008\n",
    "grid_search.best_params_\n",
    "#grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1009\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=30, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1010\n",
    "r2_score(y_train, y_predtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1011\n",
    "cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1012\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=30, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1013\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1014\n",
    "np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1015\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1016\n",
    "x=[10,14]\n",
    "x=y\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1017\n",
    "x=[10,14]\n",
    "x=y\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1018\n",
    "x=[10,12]\n",
    "x=y\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1019\n",
    "x=[10,12]\n",
    "x=y\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "#plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1020\n",
    "x=[10,12]\n",
    "x=y\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1021\n",
    "x=[10,12]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1022\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1023\n",
    "plt.scatter((y_test),(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1024\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1025\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "x=y\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1026\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1027\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index\n",
    "xtrain=xtrain[topcols]\n",
    "ytrain=ytrain[topcols]\n",
    "xtest=xtest[topcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1028\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "yltrain=(np.log(ytrain))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1029\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1030\n",
    "ytrain=train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1031\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "yltrain=(np.log(ytrain))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1032\n",
    "grid_search.best_params_\n",
    "#grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1033\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1034\n",
    "grid_search.best_params_\n",
    "#grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1035\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "yltrain=(np.log(ytrain))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain, yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1036\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1037\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1038\n",
    "np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1039\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1040\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1041\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1042\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain, ytrain)\n",
    "y_pred=regr.predict(xtest)\n",
    "#y_predtr=regr.predict(X_traind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1043\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1044\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1045\n",
    "xtest.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1046\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1047\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1048\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1049\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1050\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1051\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1052\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1053\n",
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1054\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1055\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=10000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1056\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1057\n",
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1058\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1059\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1060\n",
    "x=['YearRemodAdd','YearBuilt']\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "temptrain=xtrain\n",
    "temptest=xtest\n",
    "xtrain[x]=r[x]\n",
    "xtest[x]=ra[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1061\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1062\n",
    "xtrain[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1063\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=10000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1064\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1065\n",
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1066\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1067\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index\n",
    "#xtrain=xtrain[topcols]\n",
    "#xtest=xtest[topcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1068\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index\n",
    "#xtrain=xtrain[topcols]\n",
    "#xtest=xtest[topcols]\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1069\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1070\n",
    "xtrain=train[1:81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1071\n",
    "xtrain=train[1:81]\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1072\n",
    "xtrain=train[1:81]\n",
    "#xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1073\n",
    "xtrain=train[1:81]\n",
    "#xtrain\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1074\n",
    "xtrain=train[:,1:81]\n",
    "#xtrain\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1075\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1076\n",
    "#xtrain\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1077\n",
    "#xtrain\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1078\n",
    "temptrain.shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1079\n",
    "temptrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1080\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1081\n",
    "xtrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1082\n",
    "r[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1083\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1084\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1085\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1086\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1087\n",
    "ra=pd.read_csv(\"./testmod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1088\n",
    "ra=pd.read_csv(\"./test_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1089\n",
    "ra.shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1090\n",
    "ra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1091\n",
    "xtest=pd.read_csv(\"./test_mod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1092\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1093\n",
    "x=['YearRemodAdd','YearBuilt']\n",
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain[x]=r[x]\n",
    "xtest[x]=ra[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1094\n",
    "xtrain[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1095\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1096\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=10000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1097\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1098\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1099\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1100\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain[topcols]):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1101\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1102\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1103\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1104\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1105\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1106\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1107\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "yltrain=(np.log(ytrain))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain[topcols], yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1108\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1109\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=200)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1110\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1111\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1112\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1113\n",
    "#Train parity\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1114\n",
    "#Test parity\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1115\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain, ytrain)\n",
    "y_pred=regr.predict(xtest)\n",
    "#y_predtr=regr.predict(X_traind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1116\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], ytrain)\n",
    "y_pred=regr.predict(xtest[topcols])\n",
    "#y_predtr=regr.predict(X_traind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1117\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1118\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1119\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1120\n",
    "cat=pd.read_csv(\"./categorical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1121\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1122\n",
    "cat['encode']==hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1123\n",
    "cat['encode']=='hot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1124\n",
    "cat[cat['encode']=='hot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1125\n",
    "cat[cat['encode']=='hot']['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1126\n",
    "cat[cat['encode']=='hot']['categories'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1127\n",
    "cat[cat['encode']=='hot']['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1128\n",
    "cat[cat['encode']=='hot']['categories'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1129\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1130\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "hotcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1131\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1132\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "xtrain[hotcols].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1133\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "xtrain[hotcols].info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1134\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "xtrain[hotcols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1135\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1136\n",
    "nomcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1137\n",
    "dictlist\n",
    "#for i in range(len(dictlist)):\n",
    "   # [[key, value]] = dictlist[i].items()\n",
    "  #  scale_mapper={k: v for v, k in enumerate(value)}\n",
    "   # print(key)\n",
    "  #  print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1138\n",
    "dictlist[0]\n",
    "#for i in range(len(dictlist)):\n",
    "   # [[key, value]] = dictlist[i].items()\n",
    "  #  scale_mapper={k: v for v, k in enumerate(value)}\n",
    "   # print(key)\n",
    "  #  print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1139\n",
    "[[key, value]] = dictlist[0].items()\n",
    "value\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1140\n",
    "[[key, value]] = dictlist[0].items()\n",
    "enumerate(value)\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1141\n",
    "[[key, value]] = dictlist[0].items()\n",
    "k in enumerate(value)\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1142\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value)}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1143\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value)}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1144\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value)}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1145\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value)}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1146\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value)}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1147\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value[::-1])}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "enumerate(range(5)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1148\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value[::-1])}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "enumerate(range(5)[::-1])\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1149\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value[::-1])}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "enumerate(range(5)[::-1])\n",
    "scale,key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1150\n",
    "[[key, value]] = dictlist[0].items()\n",
    "scale={k:v for v, k in enumerate(value[::-1])}\n",
    "#scale_mapper={k: v for v, k in enumerate(value)}\n",
    "enumerate(range(5)[::-1])\n",
    "scale,value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1151\n",
    "train['MSZoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1152\n",
    "scalemapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1153\n",
    "dictlist[0]\n",
    "len(dictlist)\n",
    "for i in range(1):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1154\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    #for i in xtrain[nomcols[i]]\n",
    "        #replace with reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1155\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    #for i in xtrain[nomcols[i]]\n",
    "        #replace with reverse order\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1156\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value)}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    #for i in xtrain[nomcols[i]]\n",
    "        #replace with reverse order\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1157\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1158\n",
    "terp=train\n",
    "terst=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1159\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value)}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    #revert back\n",
    "    \n",
    "    \n",
    "    #for i in xtrain[nomcols[i]]\n",
    "    #replace with reverse order\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value)}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "    #train[key]\n",
    "    \n",
    "    #scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1160\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value)}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    #revert back\n",
    "    \n",
    "    \n",
    "    #for i in xtrain[nomcols[i]]\n",
    "    #replace with reverse order\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value)}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "    #train[key]\n",
    "    \n",
    "    #scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1161\n",
    "terp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1162\n",
    "terp['GarageYrBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1163\n",
    "terp['GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1164\n",
    "terp['GarageYrBlt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1165\n",
    "terp['GarageYrBlt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1166\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1167\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    #terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1168\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1169\n",
    "terp[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1170\n",
    "terp[key].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1171\n",
    "terp[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1172\n",
    "terp[key-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1173\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1174\n",
    "terp[key].value_counts()\n",
    "test[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1175\n",
    "terp[key].value_counts()\n",
    "xtest[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1176\n",
    "terp[key].value_counts()\n",
    "train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1177\n",
    "terp[key].value_counts()\n",
    "#train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1178\n",
    "terp[key].value_counts()\n",
    "train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1179\n",
    "terp[key].value_counts()\n",
    "#train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1180\n",
    "terp[key].value_counts(),train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1181\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1182\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1183\n",
    "terp[key].value_counts(),train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1184\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1185\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1186\n",
    "terp[key].value_counts(),train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1187\n",
    "terp[key].value_counts(),train[key].value_counts()\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1188\n",
    "terp[key].value_counts(),train[key].value_counts()\n",
    "scale_mapper\n",
    "terp[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1189\n",
    "terp[key].value_counts(),train[key].value_counts()\n",
    "scale_mapper\n",
    "terp[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1190\n",
    "terp[key].value_counts(),train[key].value_counts()\n",
    "scale_mapper\n",
    "terp[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1191\n",
    "terp[key].value_counts(),train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terp[key].value_counts()\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1192\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1193\n",
    "terp[key].value_counts(),train[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terp[key].value_counts()\n",
    "#scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 1194\n",
    "terp[key].value_counts(),train[key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1195\n",
    "terp[key].value_counts(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1196\n",
    "terp[key].value_counts(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "xtrain[key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1197\n",
    "terp[key].value_counts(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1198\n",
    "terp[key].value_counts(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "xtrain[key].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1199\n",
    "terp=xtrain\n",
    "terst=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1200\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1201\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1202\n",
    "terp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1203\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terp[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1204\n",
    "scalemapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1205\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1206\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terst[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1207\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terst[key],scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1208\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terst[key],scale_mapper,terp[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1209\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terp[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1210\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terst[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1211\n",
    "scale_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terst[key].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1212\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1213\n",
    "terp=xtrain\n",
    "terst=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1214\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value)}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1215\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1216\n",
    "terst[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1217\n",
    "terst[key].value_counts xtest[key].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1218\n",
    "terst[key].value_counts,xtest[key].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1219\n",
    "terst[key].value_counts(),xtest[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1220\n",
    "terp=xtrain\n",
    "terst=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1221\n",
    "terp=xtrain\n",
    "terst=xtest\n",
    "terst[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1222\n",
    "terp=xtrain\n",
    "terst=xtest\n",
    "terst[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1223\n",
    "xtest[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1224\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={v: k for v, k in enumerate(value)}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1225\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1226\n",
    "xtest[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1227\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1228\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1229\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1230\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1231\n",
    "terp['GarageYrBlt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1232\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1233\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts()\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1234\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts()\n",
    "xtest[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1235\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts(),xtest[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1236\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value::-1)}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1237\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate[value::-1]}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1238\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate([value::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1239\n",
    "dictlist[0]\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dictlist)):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    terp[key]=terp[key].replace(scale_mapper)\n",
    "    terst[key]=terst[key].replace(scale_mapper)\n",
    "\n",
    "    print(key)\n",
    "    print(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1240\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts(),xtest[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1241\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts(),xtest[key].value_counts()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1242\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terst[key].value_counts(),xtest[key].value_counts()\n",
    "xtrain[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1243\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1244\n",
    "for i in range(1):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for k, v in enumerate(value)}\n",
    "    terp[key]=terp[key].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1245\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1246\n",
    "terp==train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1247\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1248\n",
    "terp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1249\n",
    "todoo=terp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1250\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1251\n",
    "for i in range(1):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for k, v in enumerate(value[::-1])}\n",
    "    todoo[key]=todoo[key].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1252\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1253\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()\n",
    "toodoo[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1254\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()\n",
    "todoo[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1255\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts(),todoo[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1256\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()\n",
    "todoo[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1257\n",
    "todoo[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1258\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1259\n",
    "for i in range(1):\n",
    "\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value)}\n",
    "    todoo[key]=todoo[key].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1260\n",
    "#terp=xtrain\n",
    "#terst=xtest\n",
    "terp[key].value_counts(),xtrain[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1261\n",
    "todoo[key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1262\n",
    "train=pd.read_csv(\"./train.csv\")\n",
    "test=pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1263\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1264\n",
    "ytrain=train['SalePrice']\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salesprice is skewed to the right\n",
    "ytrain.hist(bins=50)\n",
    "plt.xlabel('SalePrice',fontsize=12)\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.title('SalePrice Histogram')\n",
    "ytrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1265\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "mask = np.zeros_like(train.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train.corr(),vmin=.2,square=True,mask=mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1266\n",
    "top correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=train.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "corr=pd.DataFrame(s)\n",
    "corr=corr.rename(columns={0: 'abs(r)'})\n",
    "corr[corr['abs(r)']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1267\n",
    "#top correlated variables with respect to salesprice\n",
    "corrdf=train.corr()\n",
    "topscorr=pd.DataFrame(corrdf[corrdf['SalePrice']>0.50]['SalePrice'].abs().sort_values(ascending=False))\n",
    "mask = np.zeros_like(train[topscorr.index].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train[topscorr.index].corr(),square=True,annot=True, mask=mask, fmt='.2f',annot_kws={'size': 10},vmin=.2)\n",
    "topscorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1268\n",
    "#About the highest R value OverallQual\n",
    "# this is an ordinal categorical variable represented by integers\n",
    "np.sort(train.OverallQual.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1269\n",
    "#Boxplots to show trends of Saleprice vs Overall Qual\n",
    "bplot_data=train[['SalePrice', 'OverallQual']]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=bplot_data)\n",
    "plt.xlabel('OverallQual',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)\n",
    "plt.title('Boxplots of Overall Qual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1270\n",
    "#Continuous variable\n",
    "train.GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1271\n",
    "#There are two outliers GrLvArea>4000, but generally there is a linear relationship\n",
    "GrLiv_data=train[['SalePrice', 'GrLivArea']]\n",
    "GrLiv_data.plot.scatter(x='GrLivArea', y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel('GrLivArea',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1272\n",
    "#Possible candidates for outliers\n",
    "train[(GrLiv_data['GrLivArea']>4000) & (GrLiv_data['SalePrice']<200000) ][['GrLivArea','OverallQual','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1273\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1274\n",
    "print(misval.shape[0],\" total missing values\" )\n",
    "print((misval['misval_train']!=0).sum(), \"missing values in training set\")\n",
    "print((misval['misval_test']!=0).sum(), \"missing values in test set\")\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1275\n",
    "train=pd.read_csv(\"./train.csv\")\n",
    "test=pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1276\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1277\n",
    "xtest=test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1278\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1279\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1280\n",
    "ytrain=train['SalePrice']\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salesprice is skewed to the right\n",
    "ytrain.hist(bins=50)\n",
    "plt.xlabel('SalePrice',fontsize=12)\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.title('SalePrice Histogram')\n",
    "ytrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1281\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "mask = np.zeros_like(train.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train.corr(),vmin=.2,square=True,mask=mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1282\n",
    "top correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=train.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "corr=pd.DataFrame(s)\n",
    "corr=corr.rename(columns={0: 'abs(r)'})\n",
    "corr[corr['abs(r)']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1283\n",
    "#top correlated variables with respect to salesprice\n",
    "corrdf=train.corr()\n",
    "topscorr=pd.DataFrame(corrdf[corrdf['SalePrice']>0.50]['SalePrice'].abs().sort_values(ascending=False))\n",
    "mask = np.zeros_like(train[topscorr.index].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train[topscorr.index].corr(),square=True,annot=True, mask=mask, fmt='.2f',annot_kws={'size': 10},vmin=.2)\n",
    "topscorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1284\n",
    "#About the highest R value OverallQual\n",
    "# this is an ordinal categorical variable represented by integers\n",
    "np.sort(train.OverallQual.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1285\n",
    "#Boxplots to show trends of Saleprice vs Overall Qual\n",
    "bplot_data=train[['SalePrice', 'OverallQual']]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=bplot_data)\n",
    "plt.xlabel('OverallQual',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)\n",
    "plt.title('Boxplots of Overall Qual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1286\n",
    "#Continuous variable\n",
    "train.GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1287\n",
    "#There are two outliers GrLvArea>4000, but generally there is a linear relationship\n",
    "GrLiv_data=train[['SalePrice', 'GrLivArea']]\n",
    "GrLiv_data.plot.scatter(x='GrLivArea', y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel('GrLivArea',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1288\n",
    "#Possible candidates for outliers\n",
    "train[(GrLiv_data['GrLivArea']>4000) & (GrLiv_data['SalePrice']<200000) ][['GrLivArea','OverallQual','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1289\n",
    "xtest=test[test.columns[1:]]\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1290\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1291\n",
    "print(misval.shape[0],\" total missing values\" )\n",
    "print((misval['misval_train']!=0).sum(), \"missing values in training set\")\n",
    "print((misval['misval_test']!=0).sum(), \"missing values in test set\")\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1292\n",
    "get_ipython().system('grep -B8 NA data_description.txt')\n",
    "#14 with NA in description 5 basement qual 4 garage qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1293\n",
    "# impute NA to category NA\n",
    "cols= ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MiscFeature'].unique(),xtest['MiscFeature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1294\n",
    "#NA and 0's match there are no NAs that are missing values!\n",
    "print(xtest[(xtest['Fireplaces']==0) & (xtest['FireplaceQu']!='NA')].shape[0],\n",
    "      train[(train['Fireplaces']==0) & (train['FireplaceQu']!='NA')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1295\n",
    "#Three missing values for Poolarea\n",
    "print(xtest[(xtest['PoolQC']=='NA') & (xtest['PoolArea']>0)].shape[0],\n",
    "train[(train['PoolQC']=='NA') & (train['PoolArea']>0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[(xtest['PoolQC']== 'NA') & (xtest['PoolArea']>0)][['OverallQual', 'PoolQC', 'PoolArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1296\n",
    "fig = sns.catplot(y='OverallQual', x=\"PoolQC\",order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)\n",
    "fig1 = sns.catplot(x='PoolQC', y=\"PoolArea\", order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1297\n",
    "#slight increase in quality vs pool qc-- give FA for all missing data\n",
    "xtest['PoolQC']=xtest['PoolQC'].replace({'NA':'Fa'})\n",
    "print(xtest[(xtest['PoolQC']=='NA') & (xtest['PoolArea']>0)].shape[0],\n",
    "train[(train['PoolQC']=='NA') & (train['PoolArea']>0)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1298\n",
    "# Training set: 81 entries with no garage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond']\n",
    "print(train.filter(regex='Garage').isna().sum())\n",
    "print('total number of entries with misvals is',\n",
    "      pd.isnull(train[cols].any(axis=1)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1299\n",
    "#Double check to make sure that all entries with no garage have zero values for \n",
    "#garagecars and garage area\n",
    "train[pd.isnull(train['GarageType'])][['GarageCars','GarageArea']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1300\n",
    "print(xtest.filter(regex='Garage').isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at all the entries with missing garagetype, check if the other entries are zero or NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtest[pd.isnull(xtest['GarageType'])][cols].notna().sum().sum(), \n",
    "xtest[pd.isnull(xtest['GarageType'])][['GarageCars','GarageArea']].sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76 entries confirmed with no garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#This confirms that there may be 2 entries with missval\n",
    "print(xtest[pd.isnull(xtest['GarageYrBlt'])][cols].notna().sum())\n",
    "print('The two potential misvals occur at',xtest[pd.isnull(xtest['GarageYrBlt'])]['GarageType'].notna().nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[pd.isnull(xtest['GarageYrBlt'])].filter(regex='Garage').iloc[[33, 55]]\n",
    "#xtest.iloc[[666,1116]].fillna('NANA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1301\n",
    "cols= ['GarageYrBlt','GarageFinish','GarageQual','GarageCond','GarageCars','GarageArea']\n",
    "for i in range(len(cols)):\n",
    "    scale_mapper = {np.nan: train[cols[i]].mode()[0]} \n",
    "    xtest[cols[i]].loc[[666,1116]]=xtest[cols[i]].replace(scale_mapper)\n",
    "    print(train[cols[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1302\n",
    "#Cannot use 0 for area! use 440 as the next most common value.\n",
    "print(train['GarageArea'].value_counts())\n",
    "xtest.loc[1116,'GarageArea']=440\n",
    "xtest.loc[[666,1116]].filter(regex='Garage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1303\n",
    "Need to remove all NA's before running imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['GarageType','GarageFinish','GarageQual','GarageCond','GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[cols].isna().sum().sum(),xtest[cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1304\n",
    "cols=train.filter(regex='Bsmt').loc[:, train.filter(regex='Bsmt').isnull().any()].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1305\n",
    "print(train.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in training set with misvals is',\n",
    "      pd.isnull(train.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total of 39 entries, there is 37 common entries that have missing values across\n",
    "and there are two unique entries that have misvals in exposure and type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1306\n",
    "train[pd.isnull(train[cols]).any(axis=1)].filter(regex='Bsmt').loc[[332,948]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1307\n",
    "#Impute 332 to Rec, it is not unfinished because all 3 bsmtfinSF >0\n",
    "print(train['BsmtFinType2'].value_counts())\n",
    "#Impute 948 to No\n",
    "print(train['BsmtExposure'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[332,'BsmtFinType2']='Rec'\n",
    "train.loc[948,'BsmtExposure']='No'\n",
    "train.loc[[332,948]].filter(regex='Bsmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1308\n",
    "print(xtest.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in test set with misvals is',\n",
    "      pd.isnull(xtest.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Fix the the NA values that are clearly meant to be 0\n",
    "cols1=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']\n",
    "#temp[temp[cols].isnull().all(axis=1)].loc[[660,728]]\n",
    "xtest.loc[[660,728],cols1]=0\n",
    "xtest.loc[[660,728],cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1309\n",
    "#And then impute the Missing values for the 7 other values\n",
    "temp=xtest[pd.isnull(xtest[cols]).any(axis=1)].filter(regex='Bsmt')\n",
    "cols=['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']\n",
    "temp[~temp[cols].isnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1310\n",
    "#Impute missing values for the 7 entries\n",
    "cols= ['BsmtQual','BsmtCond','BsmtExposure']\n",
    "ind=temp[~temp[cols].isnull().all(axis=1)].index\n",
    "for i in range(len(cols)):\n",
    "    scale_mapper = {np.nan: train[cols[i]].value_counts().keys()[0]} \n",
    "    xtest[cols[i]].loc[ind]=xtest[cols[i]].replace(scale_mapper)\n",
    "    print(train[cols[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if it worked    \n",
    "xtest[cols].loc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1311\n",
    "#Fill in the NA values\n",
    "cols=xtest.filter(regex='Bsmt').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')\n",
    "#Check to see that there are no NA values\n",
    "(train[cols].isna().sum().sum(),xtest[cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1312\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1313\n",
    "Will run simple imputation of mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage'].hist()\n",
    "plt.title('LotFrontage');\n",
    "plt.ylabel('Counts');\n",
    "plt.xlabel('LotFrontage')\n",
    "LF_mode=train['LotFrontage'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage']=train['LotFrontage'].fillna(LF_mode)\n",
    "xtest['LotFrontage']=xtest['LotFrontage'].fillna(LF_mode)\n",
    "# A second Pass could entail looking at lot variables, street variables, to learn regression for lot frontage\n",
    "#plt.scatter(x='LotArea', y='LotFrontage', data=train);\n",
    "#axes = plt.axes()\n",
    "#axes.set_xlim([0, 100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1314\n",
    "cols=['MasVnrArea','MasVnrType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[(train['MasVnrArea']<20) & (train['MasVnrArea']>0)][cols]\n",
    "xtest[(xtest['MasVnrArea']<20) & (xtest['MasVnrArea']>0)][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume that the MasVnrArea of 1 is actually meant to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1315\n",
    "#Lets assume MassVnrtype is None for the two cases where MasVnrArea=0\n",
    "train[(train['MasVnrArea']==0) &(train['MasVnrType']!='None')][cols]\n",
    "xtest[(xtest['MasVnrArea']==0) &(xtest['MasVnrType']!='None')][cols]\n",
    "train.loc[[688,1241],cols[1]]= 'None'\n",
    "xtest.loc[[859],cols[1]]= 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets also assume that all NA's are 'None and zero'\n",
    "train[train[cols].isnull().all(axis=1)][cols]\n",
    "xtest[xtest[cols].isnull().all(axis=1)][cols]\n",
    "train[cols[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols[0]]=train[cols[0]].fillna(0)\n",
    "xtest[cols[0]]=xtest[cols[0]].fillna(0)\n",
    "train[cols[1]]=train[cols[1]].fillna('None')\n",
    "xtest[cols[1]]=xtest[cols[1]].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1316\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 1317\n",
    "cols=misval.index.tolist()\n",
    "for i in range(len(cols)):\n",
    "    #print(xtest[cols[i]].fillna(xtest[cols[i]].value_counts()[0]))\n",
    "    xtest[cols[i]]=xtest[cols[i]].fillna(train[cols[i]].value_counts().keys()[0])\n",
    "    train[cols[i]]=train[cols[i]].fillna(train[cols[i]].value_counts().keys()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1318\n",
    "# NO missing Values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1319\n",
    "import re\n",
    "file=open('./categorical.txt','r')\n",
    "stringlist=file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1320\n",
    "dictlist=[]\n",
    "for i in range(len(stringlist)):\n",
    "    value=[]\n",
    "    #if there is no spaces in the line entry, add as key\n",
    "    if re.match('^\\S', stringlist[i]):\n",
    "        key=stringlist[i]\n",
    "        n=i\n",
    "        #add all entries that have a space as a value \n",
    "        for j in range(len(stringlist[n+1:])):\n",
    "            if re.match('^\\s',stringlist[n+1:][j]):\n",
    "                value.append(stringlist[n+1:][j].split(maxsplit=1)[0])  \n",
    "        #break until the next key is observed\n",
    "            elif re.match('^\\S',stringlist[n+1:][j]):\n",
    "                break       \n",
    "        dictlist.append({key: value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1321\n",
    "dictlist[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1322\n",
    "dictlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1323\n",
    "#dictlist.pop(0,14,13) remove all the numerical values\n",
    "dictlist.pop(0)\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1324\n",
    "dictlist[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1325\n",
    "#dictlist.pop(0,14,13) remove all the numerical values\n",
    "dictlist.pop(14)\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1326\n",
    "dictlist[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1327\n",
    "#dictlist.pop(0,14,13) remove all the numerical values\n",
    "dictlist.pop(13)\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1328\n",
    "dictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1329\n",
    "for i in range(len(dictlist)):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value::-1)}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    train[key]=train[key].replace(scale_mapper)\n",
    "    xtest[key]=xtest[key].replace(scale_mapper)\n",
    "#train[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1330\n",
    "for i in range(len(dictlist)):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    train[key]=train[key].replace(scale_mapper)\n",
    "    xtest[key]=xtest[key].replace(scale_mapper)\n",
    "#train[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1331\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "x=error_cols[9]\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1332\n",
    "error_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1333\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "error_cols\n",
    "#train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1334\n",
    "train[error_cols[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1335\n",
    "train[error_cols[0]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1336\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'C (all)': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1337\n",
    "train[error_cols[0]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1338\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'C (all)': 6}\n",
    "x=error_cols[0]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1339\n",
    "train[error_cols[1]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1340\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'NAmes': 8}\n",
    "x=error_cols[1]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1341\n",
    "train[error_cols[2]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1342\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Twnhs': 0,'Duplex':2,'2fmCon':3}\n",
    "x=error_cols[1]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1343\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Twnhs': 0,'Duplex':2,'2fmCon':3}\n",
    "x=error_cols[2]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1344\n",
    "train[error_cols[2]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1345\n",
    "train[error_cols[1]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1346\n",
    "train[error_cols[3]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1347\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Twnhs': 0,'Duplex':2,'2fmCon':3}\n",
    "x=error_cols[3]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1348\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Wd Sdng':1}\n",
    "x=error_cols[3]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1349\n",
    "train[error_cols[4]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1350\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Wd Sdng':1, 'Wd Shng':0, 'CmentBd':11, 'Brk Cmn':14}\n",
    "x=error_cols[3]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1351\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Wd Sdng':1, 'Wd Shng':0, 'CmentBd':11, 'Brk Cmn':14}\n",
    "x=error_cols[4]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1352\n",
    "train[error_cols[4]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1353\n",
    "train[error_cols[5]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1354\n",
    "train[error_cols[6]].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1355\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'NA':0}\n",
    "x=error_cols[6]    \n",
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1356\n",
    "train[error_cols[6]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1357\n",
    "train[error_cols[7]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1358\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1359\n",
    "error_cols=train.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "error_cols\n",
    "#train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1360\n",
    "train[error_cols[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1361\n",
    "train[error_cols[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1362\n",
    "train[error_cols[1]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1363\n",
    "train[error_cols[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1364\n",
    "#Test to make sure that that the encoding worked\n",
    "temp=pd.read_csv(\"./train.csv\")\n",
    "x='Functional'\n",
    "temp[x].value_counts(),train[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1365\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1366\n",
    "error_cols=xtest.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "error_cols\n",
    "#train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1367\n",
    "xtest[error_cols[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1368\n",
    "xtest[error_cols[1]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1369\n",
    "xtest[error_cols[2]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1370\n",
    "xtest[error_cols[3]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1371\n",
    "xtest[error_cols[4]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1372\n",
    "xtest['Condition2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1373\n",
    "fig = sns.boxplot(y='SalePrice', x=\"MSSubClass\", data=train)\n",
    "#MSsubclass is not ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1374\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1375\n",
    "x='MoSold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1376\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 1377\n",
    "#Replace yr sold with num values 2006: 0,2007:1,2008:2,2009:3, 2010:4\n",
    "# will need to one hot encode for regression\n",
    "x='YrSold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {2006: 0,2007:1,2008:2,2009:3, 2010:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1378\n",
    "temp['GarageYrBlt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1379\n",
    "test['GarageYrBlt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1380\n",
    "train['GarageYrBlt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1381\n",
    "train.info()\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1382\n",
    "Change rest of the objects into int64, Now everything is numerically encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['Heating','BsmtCond','GarageQual','MiscFeature','RoofMatl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].astype('int64')\n",
    "xtest[x]=xtest[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1383\n",
    "train.info()\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1384\n",
    "xtrain=train[cols[1:81]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1385\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1386\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1387\n",
    "xtrain=train[cols[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1388\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1389\n",
    "xtrain=train[cols[[1:]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1390\n",
    "xtrain=train[cols[[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1391\n",
    "xtrain=train[cols[[1:]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1392\n",
    "xtrain=train[columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1393\n",
    "xtrain=train[traincolumns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1394\n",
    "xtrain=train[train.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1395\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1396\n",
    "xtrain=train[train.columns[1:81]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1397\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1398\n",
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1399\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1400\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1401\n",
    "train\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1402\n",
    "xtrain=train[train.columns[1:80]]\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1403\n",
    "#train_mod and xtest_mod \n",
    "train.to_csv('train_v1.csv',index=False)\n",
    "xtest.to_csv('test_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1404\n",
    "xtrain=train[train.columns[1:80]]\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1405\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1406\n",
    "train['GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1407\n",
    "train['GarageYrBlt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1408\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=200)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1409\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1410\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1411\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1412\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1413\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1414\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1415\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "nomcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1416\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "nomcols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1417\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1418\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1419\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1420\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1421\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1422\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1423\n",
    "train.columns\n",
    "nomcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1424\n",
    "train.columns,nomcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1425\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1426\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1427\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "train[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1428\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "cols = [col for col in df.columns if col not in hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1429\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "cols = [col for col in train.columns if col not in hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1430\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "cols = [col for col in train.columns if col not in hotcols]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1431\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1432\n",
    "cat['categories'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1433\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in train.columns if col not in catcols]\n",
    "intcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1434\n",
    "train[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1435\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1436\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in xtrain.columns if col not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1437\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1438\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1439\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1440\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data=scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1441\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1442\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1443\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols[0]]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data=scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1444\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data=scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1445\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data=scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1446\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1447\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1448\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data[[intcols]]=scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1449\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data[[intcols]]=scaler.fit_transform(data.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1450\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[intcols]]=scaler.fit_transform(data.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1451\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1452\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=scaler.fit_transform(data.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1453\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1454\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1455\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1456\n",
    "pd.DataFrame(data, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1457\n",
    "pd.DataFrame(data, columns=intcols)['LotFrontage'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1458\n",
    "xtest['LotFrontage'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1459\n",
    "pd.DataFrame(data, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1460\n",
    "xtrain[intcols]=pd.DataFrame(data, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1461\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1462\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1463\n",
    "xtrain[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1464\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in xtrain.columns if col not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1465\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=xtrain[intcols]\n",
    "scaler = StandardScaler()\n",
    "data=scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1466\n",
    "xtrain[intcols]=pd.DataFrame(data, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1467\n",
    "xtrain[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1468\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1469\n",
    "xtrain[hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1470\n",
    "xtrain['hot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1471\n",
    "xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1472\n",
    "temptest=scaler.transform(temptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1473\n",
    "temptest=xtest[intcols]\n",
    "temptest=scaler.transform(temptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1474\n",
    "xtest[intcols]=pd.DataFrame(temptest, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1475\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1476\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1477\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtrain_sscale.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1478\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1479\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1480\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=2, random_state=0, n_estimators=200)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1481\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1482\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(15).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1483\n",
    "xtrain['KitchenQual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1484\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(30).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1485\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(30).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1486\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "yltrain=(np.log(ytrain))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain[topcols], yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1487\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1488\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1489\n",
    "grid_search.best_params_,grid_search.best_score_\n",
    "y_pred=grid_search.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1490\n",
    "grid_search.best_params_,grid_search.best_score_\n",
    "#y_pred=grid_search.predict(xtest[topcols])\n",
    "#y_pred=grid_search.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1491\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1492\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1493\n",
    "np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1494\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1495\n",
    "np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1496\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1497\n",
    "#Train parity\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1498\n",
    "#Test parity\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1499\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], ytrain)\n",
    "y_pred=regr.predict(xtest[topcols])\n",
    "#y_predtr=regr.predict(X_traind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1500\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1501\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1502\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1503\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1504\n",
    "#Linear Regression---> Onehot non nominal variables, \n",
    "xtrain[nomcols]\n",
    "#standardscale int values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1505\n",
    "#Linear Regression---> Onehot non nominal variables, \n",
    "xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1506\n",
    "#Linear Regression---> Onehot non nominal variables, \n",
    "xtrain[hotcols]\n",
    "pd.get_dummies(xtrain[hotcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1507\n",
    "#Linear Regression---> Onehot non nominal variables, \n",
    "#xtrain[hotcols]\n",
    "pd.get_dummies(xtrain[hotcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1508\n",
    "#Linear Regression---> Onehot non nominal variables, \n",
    "#xtrain[hotcols]\n",
    "df=pd.get_dummies(xtrain[hotcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1509\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1510\n",
    "df\n",
    "xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1511\n",
    "df\n",
    "#xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1512\n",
    "df\n",
    "xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1513\n",
    "#Linear Regression---> Onehot non nominal variables, \n",
    "#xtrain[hotcols]\n",
    "df=pd.get_dummies(xtrain[hotcols],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1514\n",
    "df\n",
    "xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1515\n",
    "df\n",
    "#xtrain[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1516\n",
    "hotcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1517\n",
    "hotcols.shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1518\n",
    "hotcols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1519\n",
    "len(hotcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1520\n",
    "df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n",
    "              'C': [1, 2, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1521\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1522\n",
    "pd.get_dummies(df,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1523\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1524\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1525\n",
    "df=xtrain[hotcols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1526\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1527\n",
    "df=xtrain[hotcols].astype(str)\n",
    "pd.get_dummies(xtrain[hotcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1528\n",
    "pd.get_dummies(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1529\n",
    "pd.get_dummies(df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1530\n",
    "df=xtrain[hotcols].astype(str)\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1531\n",
    "df=xtrain[hotcols].astype(str)\n",
    "dt=xtest[hotcols].astype(str)\n",
    "hottrain=pd.get_dummies(df)\n",
    "hottest=pd.get_dummies(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1532\n",
    "hottest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1533\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1534\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1535\n",
    "temptest=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1536\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1537\n",
    "temptest.drop([hotcols], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1538\n",
    "hotcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1539\n",
    "temptest.drop(hotcols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1540\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1541\n",
    "pd.concat([temptest, hottest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1542\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1543\n",
    "temptest=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1544\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1545\n",
    "temptest.drop(hotcols, axis=1, inplace=True)\n",
    "#pd.concat([temptest, hottest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1546\n",
    "temptest=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1547\n",
    "temptest.drop(hotcols, axis=1, inplace=True)\n",
    "#pd.concat([temptest, hottest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1548\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1549\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1550\n",
    "#temptest.drop(hotcols, axis=1, inplace=True)\n",
    "temptest=pd.concat([temptest, hottest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1551\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1552\n",
    "temptest=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1553\n",
    "temptest=xtest\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1554\n",
    "#temptest.drop(hotcols, axis=1, inplace=True)\n",
    "temptest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1555\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1556\n",
    "temptest[hotcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1557\n",
    "temptest[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1558\n",
    "hottrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1559\n",
    "hottest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1560\n",
    "hottrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1561\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1562\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1563\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1564\n",
    "hottrain=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1565\n",
    "hottrain=pd.get_dummies(df)\n",
    "hottrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1566\n",
    "hottrain=pd.get_dummies(df)\n",
    "hottest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1567\n",
    "hottrain=pd.get_dummies(dt)\n",
    "hottest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1568\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1569\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1570\n",
    "#temptest.drop(hotcols, axis=1, inplace=True)\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1571\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1572\n",
    "pd.read_csv('xtest_scale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1573\n",
    "pd.read_csv('xtest_sscale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1574\n",
    "xtest=pd.read_csv('xtest_sscale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1575\n",
    "#temptest.drop(hotcols, axis=1, inplace=True)\n",
    "xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1576\n",
    "df=xtrain[hotcols].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hottrain=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "temptest=xtest\n",
    "temptest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1577\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1578\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1579\n",
    "temptest\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1580\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1581\n",
    "temptest\n",
    "hotcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1582\n",
    "temptest\n",
    "nomcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1583\n",
    "temptest\n",
    "hotcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1584\n",
    "temptest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1585\n",
    "df=xtrain[hotcols].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hottrain=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "temptest=xtest\n",
    "temptest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1586\n",
    "temptest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1587\n",
    "df=xtrain[hotcols].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hottrain=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "temptest=xtest\n",
    "temptest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1588\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1589\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1590\n",
    "temptest.drop(hotcols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1591\n",
    "temptest.drop(hotcols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1592\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1593\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1594\n",
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "temptrain=xtrain\n",
    "temptrain=pd.concat([xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "temptest=xtest\n",
    "temptest=pd.DataFrame()\n",
    "#temptest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1595\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1596\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1597\n",
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "temptrain=xtrain\n",
    "temptrain=pd.concat([xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "temptest=pd.DataFrame()\n",
    "temptest=xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temptest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1598\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1599\n",
    "temptest.drop(hotcols, axis=1, inplace=True)\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1600\n",
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "temptrain=xtrain\n",
    "temptrain=pd.concat([xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "temptest=pd.DataFrame()\n",
    "temptest=xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temptest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1601\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1602\n",
    "temptest.drop(hotcols, axis=1, inplace=True)\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1603\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1604\n",
    "temptest\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1605\n",
    "temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1606\n",
    "hottest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1607\n",
    "newtest=pd.DataFrame()\n",
    "newtest=pd.concat([xtest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1608\n",
    "newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1609\n",
    "newtest([hotcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1610\n",
    "newtest[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1611\n",
    "newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1612\n",
    "xtest=newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1613\n",
    "#\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1614\n",
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "xtrain=pd.concat([xtrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1615\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1616\n",
    "#hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "xtrain=pd.concat([xtrain,hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1617\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1618\n",
    "hottrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1619\n",
    "#hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1620\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1621\n",
    "#\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1622\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1623\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('xtest_sscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1624\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('xtest_sscale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1625\n",
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "#xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1626\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1627\n",
    "xtrain=pd.read_csv('xtest_sscale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1628\n",
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "#xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1629\n",
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "#xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1630\n",
    "#hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1631\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1632\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1633\n",
    "xtrain\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1634\n",
    "xtrain\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1635\n",
    "#xtrain\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1636\n",
    "#xtrain\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1637\n",
    "#xtrain\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1638\n",
    "#xtrain\n",
    "xtrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1639\n",
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1640\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1641\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1642\n",
    "pd.read_csv('xtrain_sscale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1643\n",
    "ar=pd.read_csv('xtrain_sscale.csv')\n",
    "ar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1644\n",
    "ar=pd.read_csv('xtrain_sscale.csv')\n",
    "ar['YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1645\n",
    "ar=pd.read_csv('xtrain_sscale.csv')\n",
    "ar['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1646\n",
    "xtrain['MoSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1647\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1648\n",
    "ar=pd.read_csv('xtrain_sscale.csv')\n",
    "ar['YrBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1649\n",
    "ar=pd.read_csv('xtrain_sscale.csv')\n",
    "ar['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1650\n",
    "ar=pd.read_csv('xtrain_sscale.csv')\n",
    "ar['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1651\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1652\n",
    "xtrain=pd.read_csv('xtrain_sscale.csv')\n",
    "xtrain['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1653\n",
    "One hot encoded AND num coded train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "xtest.drop(hotcols, axis=1, inplace=True)\n",
    "xtest=pd.concat([xtest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "#xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1654\n",
    "hottrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1655\n",
    "One hot encoded AND num coded train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "xtest.drop(hotcols, axis=1, inplace=True)\n",
    "xtest=pd.concat([xtest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1656\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1657\n",
    "xtrain.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1658\n",
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1659\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1660\n",
    "xtrain=pd.read_csv('xtest_sscale.csv')\n",
    "xtrain['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1661\n",
    "xtest=pd.read_csv('xtest_sscale.csv')\n",
    "xtrain['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1662\n",
    "xtest=pd.read_csv('xtest_sscale.csv')\n",
    "xtest['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1663\n",
    "xtest=pd.read_csv('xtest_sscale.csv')\n",
    "#xtest['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1664\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1665\n",
    "xtest['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1666\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1667\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtrain[intcols]\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1668\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtrain[intcols]\n",
    "#xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1669\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtrain[intcols]\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1670\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtrain[intcols]\n",
    "#xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1671\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1672\n",
    "xtrain=pd.read_csv('xtrain_sscale.csv')\n",
    "#xtest['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1673\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1674\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1675\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtrain[intcols]\n",
    "#xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1676\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#temptrain=scaler.fit_transform(xtrain[intcols])\n",
    "temptest=scaler.transform(xtest[intcols])\n",
    "xtest[intcols]=pd.DataFrame(temptest, columns=intcols)\n",
    "#xtrain[intcols]=pd.DataFrame(temptrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1677\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1678\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#temptrain=scaler.fit_transform(xtrain[intcols])\n",
    "temptest=scaler.transform(xtest[intcols])\n",
    "xtest[intcols]=pd.DataFrame(temptest, columns=intcols)\n",
    "#xtrain[intcols]=pd.DataFrame(temptrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1679\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "#xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1680\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1681\n",
    "get_ipython().system('ls')\n",
    "pd.read_csv('test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1682\n",
    "get_ipython().system('ls')\n",
    "xtest=pd.read_csv('test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1683\n",
    "get_ipython().system('ls')\n",
    "xtest=pd.read_csv('test_v2.csv')\n",
    "xtrain=pd.read_csv('train_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1684\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "temptrain=scaler.fit(xtrain[intcols])\n",
    "#temptest=scaler.transform(xtest[intcols])\n",
    "#xtest[intcols]=pd.DataFrame(temptest, columns=intcols)\n",
    "#xtrain[intcols]=pd.DataFrame(temptrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1685\n",
    "temptrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1686\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "scl=scaler.fit(xtrain[intcols])\n",
    "ttrain=scaler.transform(xtrain[intcols])\n",
    "#temptest=scaler.transform(xtest[intcols])\n",
    "#xtest[intcols]=pd.DataFrame(temptest, columns=intcols)\n",
    "#xtrain[intcols]=pd.DataFrame(temptrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1687\n",
    "ttrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1688\n",
    "pd.DataFrame(ttrain,columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1689\n",
    "pd.DataFrame(ttrain,columns=intcols)\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1690\n",
    "pd.DataFrame(ttrain,columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1691\n",
    "pd.DataFrame(ttrain,columns=intcols)\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1692\n",
    "pd.DataFrame(ttrain,columns=intcols)\n",
    "ttrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1693\n",
    "pd.DataFrame(ttrain,columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1694\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "scl=scaler.fit(xtrain[intcols])\n",
    "ttrain=scaler.transform(xtrain[intcols])\n",
    "ttest=scaler.transform(xtest[intcols])\n",
    "#xtest[intcols]=pd.DataFrame(temptest, columns=intcols)\n",
    "#xtrain[intcols]=pd.DataFrame(temptrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1695\n",
    "pd.DataFrame(ttest,columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1696\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1697\n",
    "xtrain[xtrain.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1698\n",
    "xtrain=xtrain[xtrain.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1699\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "scl=scaler.fit(xtrain[intcols])\n",
    "ttrain=scaler.transform(xtrain[intcols])\n",
    "ttest=scaler.transform(xtest[intcols])\n",
    "xtest[intcols]=pd.DataFrame(ttest, columns=intcols)\n",
    "xtrain[intcols]=pd.DataFrame(ttrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1700\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1701\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1702\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1703\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1704\n",
    "#xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1705\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1706\n",
    "np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1707\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1708\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1709\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], ytrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1710\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1711\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1712\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1713\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1714\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1715\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1716\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], ytrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1717\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1718\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1719\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1720\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1721\n",
    "xtrain[topcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1722\n",
    "xtest[topcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1723\n",
    "xtrain[topcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1724\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1725\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1726\n",
    "pd.read_csv('xtrain_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1727\n",
    "pd.read_csv('xtrain_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1728\n",
    "pd.read_csv('train_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1729\n",
    "xtrain=pd.read_csv('train_v1.csv')\n",
    "xtrain=xtrain[xtrain.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1730\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1731\n",
    "xtest=pd.read_csv('test_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1732\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1733\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "scl=scaler.fit(xtrain[intcols])\n",
    "ttrain=scaler.transform(xtrain[intcols])\n",
    "ttest=scaler.transform(xtest[intcols])\n",
    "xtest[intcols]=pd.DataFrame(ttest, columns=intcols)\n",
    "xtrain[intcols]=pd.DataFrame(ttrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1734\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1735\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1736\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1737\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1738\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1739\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1740\n",
    "np.mean(cvscores)\n",
    "#cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1741\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1742\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(30).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1743\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1744\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1745\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=xtrain.columns)\n",
    "feat_importances.nlargest(30).plot(kind='bar')\n",
    "topcols=feat_importances.nlargest(30).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1746\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1747\n",
    "np.mean(cvscores)\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1748\n",
    "np.mean(cvscores),cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1749\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "yltrain=(np.log(ytrain))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain[topcols], yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1750\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1751\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=60, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1752\n",
    "np.mean(cvscores),cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1753\n",
    "#Train parity\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1754\n",
    "#Test parity\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1755\n",
    "regr = RandomForestRegressor(max_depth=60, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1756\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1757\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1758\n",
    "regr = RandomForestRegressor(max_depth=60, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1759\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1760\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1761\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1762\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1763\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1764\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1765\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1766\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1767\n",
    "xtest\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1768\n",
    "xtest\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1769\n",
    "xtest\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1770\n",
    "xtest\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1771\n",
    "xtest[topcols]\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1772\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], ytrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1773\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1774\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1775\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1776\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1777\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1778\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1779\n",
    "train=pd.read_csv(\"./train.csv\")\n",
    "test=pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1780\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1781\n",
    "xtest=test[test.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1782\n",
    "ytrain=train['SalePrice']\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salesprice is skewed to the right\n",
    "ytrain.hist(bins=50)\n",
    "plt.xlabel('SalePrice',fontsize=12)\n",
    "plt.ylabel('Counts',fontsize=12)\n",
    "plt.title('SalePrice Histogram')\n",
    "ytrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1783\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "mask = np.zeros_like(train.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train.corr(),vmin=.2,square=True,mask=mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1784\n",
    "top correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=train.corr().abs().unstack().sort_values(ascending=False).drop_duplicates()\n",
    "corr=pd.DataFrame(s)\n",
    "corr=corr.rename(columns={0: 'abs(r)'})\n",
    "corr[corr['abs(r)']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1785\n",
    "#top correlated variables with respect to salesprice\n",
    "corrdf=train.corr()\n",
    "topscorr=pd.DataFrame(corrdf[corrdf['SalePrice']>0.50]['SalePrice'].abs().sort_values(ascending=False))\n",
    "mask = np.zeros_like(train[topscorr.index].corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(train[topscorr.index].corr(),square=True,annot=True, mask=mask, fmt='.2f',annot_kws={'size': 10},vmin=.2)\n",
    "topscorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1786\n",
    "#About the highest R value OverallQual\n",
    "# this is an ordinal categorical variable represented by integers\n",
    "np.sort(train.OverallQual.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1787\n",
    "#Boxplots to show trends of Saleprice vs Overall Qual\n",
    "bplot_data=train[['SalePrice', 'OverallQual']]\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=bplot_data)\n",
    "plt.xlabel('OverallQual',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)\n",
    "plt.title('Boxplots of Overall Qual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1788\n",
    "#Continuous variable\n",
    "train.GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1789\n",
    "#There are two outliers GrLvArea>4000, but generally there is a linear relationship\n",
    "GrLiv_data=train[['SalePrice', 'GrLivArea']]\n",
    "GrLiv_data.plot.scatter(x='GrLivArea', y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel('GrLivArea',fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1790\n",
    "#Possible candidates for outliers\n",
    "train[(GrLiv_data['GrLivArea']>4000) & (GrLiv_data['SalePrice']<200000) ][['GrLivArea','OverallQual','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1791\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1792\n",
    "print(misval.shape[0],\" total missing values\" )\n",
    "print((misval['misval_train']!=0).sum(), \"missing values in training set\")\n",
    "print((misval['misval_test']!=0).sum(), \"missing values in test set\")\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1793\n",
    "# impute NA to category NA\n",
    "cols= ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MiscFeature'].unique(),xtest['MiscFeature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1794\n",
    "#NA and 0's match there are no NAs that are missing values!\n",
    "print(xtest[(xtest['Fireplaces']==0) & (xtest['FireplaceQu']!='NA')].shape[0],\n",
    "      train[(train['Fireplaces']==0) & (train['FireplaceQu']!='NA')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1795\n",
    "#Three missing values for Poolarea\n",
    "print(xtest[(xtest['PoolQC']=='NA') & (xtest['PoolArea']>0)].shape[0],\n",
    "train[(train['PoolQC']=='NA') & (train['PoolArea']>0)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[(xtest['PoolQC']== 'NA') & (xtest['PoolArea']>0)][['OverallQual', 'PoolQC', 'PoolArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1796\n",
    "fig = sns.catplot(y='OverallQual', x=\"PoolQC\",order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)\n",
    "fig1 = sns.catplot(x='PoolQC', y=\"PoolArea\", order=[\"NA\", \"Fa\",\"TA\", \"Gd\",\"Ex\"], data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1797\n",
    "#slight increase in quality vs pool qc-- give FA for all missing data\n",
    "xtest['PoolQC']=xtest['PoolQC'].replace({'NA':'Fa'})\n",
    "print(xtest[(xtest['PoolQC']=='NA') & (xtest['PoolArea']>0)].shape[0],\n",
    "train[(train['PoolQC']=='NA') & (train['PoolArea']>0)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1798\n",
    "# Training set: 81 entries with no garage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond']\n",
    "print(train.filter(regex='Garage').isna().sum())\n",
    "print('total number of entries with misvals is',\n",
    "      pd.isnull(train[cols].any(axis=1)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1799\n",
    "#Double check to make sure that all entries with no garage have zero values for \n",
    "#garagecars and garage area\n",
    "train[pd.isnull(train['GarageType'])][['GarageCars','GarageArea']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1800\n",
    "print(xtest.filter(regex='Garage').isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at all the entries with missing garagetype, check if the other entries are zero or NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtest[pd.isnull(xtest['GarageType'])][cols].notna().sum().sum(), \n",
    "xtest[pd.isnull(xtest['GarageType'])][['GarageCars','GarageArea']].sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76 entries confirmed with no garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#This confirms that there may be 2 entries with missval\n",
    "print(xtest[pd.isnull(xtest['GarageYrBlt'])][cols].notna().sum())\n",
    "print('The two potential misvals occur at',xtest[pd.isnull(xtest['GarageYrBlt'])]['GarageType'].notna().nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest[pd.isnull(xtest['GarageYrBlt'])].filter(regex='Garage').iloc[[33, 55]]\n",
    "#xtest.iloc[[666,1116]].fillna('NANA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1801\n",
    "cols= ['GarageYrBlt','GarageFinish','GarageQual','GarageCond','GarageCars','GarageArea']\n",
    "for i in range(len(cols)):\n",
    "    scale_mapper = {np.nan: train[cols[i]].mode()[0]} \n",
    "    xtest[cols[i]].loc[[666,1116]]=xtest[cols[i]].replace(scale_mapper)\n",
    "    print(train[cols[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1802\n",
    "#Cannot use 0 for area! use 440 as the next most common value.\n",
    "print(train['GarageArea'].value_counts())\n",
    "xtest.loc[1116,'GarageArea']=440\n",
    "xtest.loc[[666,1116]].filter(regex='Garage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1803\n",
    "Need to remove all NA's before running imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['GarageType','GarageFinish','GarageQual','GarageCond','GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[cols].isna().sum().sum(),xtest[cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1804\n",
    "cols=train.filter(regex='Bsmt').loc[:, train.filter(regex='Bsmt').isnull().any()].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1805\n",
    "print(train.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in training set with misvals is',\n",
    "      pd.isnull(train.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total of 39 entries, there is 37 common entries that have missing values across\n",
    "and there are two unique entries that have misvals in exposure and type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1806\n",
    "train[pd.isnull(train[cols]).any(axis=1)].filter(regex='Bsmt').loc[[332,948]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1807\n",
    "#Impute 332 to Rec, it is not unfinished because all 3 bsmtfinSF >0\n",
    "print(train['BsmtFinType2'].value_counts())\n",
    "#Impute 948 to No\n",
    "print(train['BsmtExposure'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[332,'BsmtFinType2']='Rec'\n",
    "train.loc[948,'BsmtExposure']='No'\n",
    "train.loc[[332,948]].filter(regex='Bsmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1808\n",
    "print(xtest.filter(regex='Bsmt').isna().sum())\n",
    "print('total number of entries in test set with misvals is',\n",
    "      pd.isnull(xtest.filter(regex='Bsmt')).any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Fix the the NA values that are clearly meant to be 0\n",
    "cols1=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']\n",
    "#temp[temp[cols].isnull().all(axis=1)].loc[[660,728]]\n",
    "xtest.loc[[660,728],cols1]=0\n",
    "xtest.loc[[660,728],cols1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1809\n",
    "#And then impute the Missing values for the 7 other values\n",
    "temp=xtest[pd.isnull(xtest[cols]).any(axis=1)].filter(regex='Bsmt')\n",
    "cols=['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']\n",
    "temp[~temp[cols].isnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1810\n",
    "#Impute missing values for the 7 entries\n",
    "cols= ['BsmtQual','BsmtCond','BsmtExposure']\n",
    "ind=temp[~temp[cols].isnull().all(axis=1)].index\n",
    "for i in range(len(cols)):\n",
    "    scale_mapper = {np.nan: train[cols[i]].value_counts().keys()[0]} \n",
    "    xtest[cols[i]].loc[ind]=xtest[cols[i]].replace(scale_mapper)\n",
    "    print(train[cols[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if it worked    \n",
    "xtest[cols].loc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1811\n",
    "#Fill in the NA values\n",
    "cols=xtest.filter(regex='Bsmt').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols]=train[cols].fillna('NA')\n",
    "xtest[cols]=xtest[cols].fillna('NA')\n",
    "#Check to see that there are no NA values\n",
    "(train[cols].isna().sum().sum(),xtest[cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1812\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1813\n",
    "Will run simple imputation of mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage'].hist()\n",
    "plt.title('LotFrontage');\n",
    "plt.ylabel('Counts');\n",
    "plt.xlabel('LotFrontage')\n",
    "LF_mode=train['LotFrontage'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage']=train['LotFrontage'].fillna(LF_mode)\n",
    "xtest['LotFrontage']=xtest['LotFrontage'].fillna(LF_mode)\n",
    "# A second Pass could entail looking at lot variables, street variables, to learn regression for lot frontage\n",
    "#plt.scatter(x='LotArea', y='LotFrontage', data=train);\n",
    "#axes = plt.axes()\n",
    "#axes.set_xlim([0, 100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1814\n",
    "cols=['MasVnrArea','MasVnrType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[(train['MasVnrArea']<20) & (train['MasVnrArea']>0)][cols]\n",
    "xtest[(xtest['MasVnrArea']<20) & (xtest['MasVnrArea']>0)][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume that the MasVnrArea of 1 is actually meant to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1815\n",
    "#Lets assume MassVnrtype is None for the two cases where MasVnrArea=0\n",
    "train[(train['MasVnrArea']==0) &(train['MasVnrType']!='None')][cols]\n",
    "xtest[(xtest['MasVnrArea']==0) &(xtest['MasVnrType']!='None')][cols]\n",
    "train.loc[[688,1241],cols[1]]= 'None'\n",
    "xtest.loc[[859],cols[1]]= 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets also assume that all NA's are 'None and zero'\n",
    "train[train[cols].isnull().all(axis=1)][cols]\n",
    "xtest[xtest[cols].isnull().all(axis=1)][cols]\n",
    "train[cols[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols[0]]=train[cols[0]].fillna(0)\n",
    "xtest[cols[0]]=xtest[cols[0]].fillna(0)\n",
    "train[cols[1]]=train[cols[1]].fillna('None')\n",
    "xtest[cols[1]]=xtest[cols[1]].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1816\n",
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 1817\n",
    "cols=misval.index.tolist()\n",
    "for i in range(len(cols)):\n",
    "    #print(xtest[cols[i]].fillna(xtest[cols[i]].value_counts()[0]))\n",
    "    xtest[cols[i]]=xtest[cols[i]].fillna(train[cols[i]].value_counts().keys()[0])\n",
    "    train[cols[i]]=train[cols[i]].fillna(train[cols[i]].value_counts().keys()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1818\n",
    "# NO missing Values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval=pd.DataFrame()\n",
    "misval['misval_test']=xtest.isnull().sum()\n",
    "misval['misval_test_%']=round(100*pd.DataFrame(xtest.isnull().sum())/(1459),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['misval_train']=pd.DataFrame(train.isnull().sum())\n",
    "misval['misval_train_%']=round(100*pd.DataFrame(train.isnull().sum())/(1460),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misval['total_misval']=misval['misval_test']+misval['misval_train']\n",
    "misval['total_misval_%']=round((100*misval['total_misval'])/(1460+1459),1)\n",
    "misval=misval[misval['total_misval']>0].sort_values(by='total_misval_%',ascending=False)\n",
    "misval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1819\n",
    "import re\n",
    "file=open('./categorical.txt','r')\n",
    "stringlist=file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1820\n",
    "dictlist=[]\n",
    "for i in range(len(stringlist)):\n",
    "    value=[]\n",
    "    #if there is no spaces in the line entry, add as key\n",
    "    if re.match('^\\S', stringlist[i]):\n",
    "        key=stringlist[i]\n",
    "        n=i\n",
    "        #add all entries that have a space as a value \n",
    "        for j in range(len(stringlist[n+1:])):\n",
    "            if re.match('^\\s',stringlist[n+1:][j]):\n",
    "                value.append(stringlist[n+1:][j].split(maxsplit=1)[0])  \n",
    "        #break until the next key is observed\n",
    "            elif re.match('^\\S',stringlist[n+1:][j]):\n",
    "                break       \n",
    "        dictlist.append({key: value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1821\n",
    "#dictlist.pop(0,14,13) remove all the numerical values\n",
    "len(dictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1822\n",
    "#dictlist.pop(0,14,13) remove all the numerical values\n",
    "len(dictlist)\n",
    "dictlist.pop(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1823\n",
    "#dictlist.pop(0,14,13) remove all the numerical values\n",
    "len(dictlist)\n",
    "dictlist.pop(14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1824\n",
    "#dictlist.pop(0,14,13) remove all the numerical values\n",
    "len(dictlist)\n",
    "dictlist.pop(13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1825\n",
    "dictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1826\n",
    "for i in range(len(dictlist)):\n",
    "    [[key, value]] = dictlist[i].items()\n",
    "    scale_mapper={k: v for v, k in enumerate(value[::-1])}\n",
    "    print(key)\n",
    "    print(scale_mapper)\n",
    "    train[key]=train[key].replace(scale_mapper)\n",
    "    xtest[key]=xtest[key].replace(scale_mapper)\n",
    "#train[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1827\n",
    "error_cols=xtest.select_dtypes(exclude=['int64','float']).columns.tolist()\n",
    "error_cols\n",
    "#train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1828\n",
    "xtest[error_cols[4]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1829\n",
    "xtest[error_cols[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1830\n",
    "x=error_cols[0]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1831\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'C (all)':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1832\n",
    "x=error_cols[1]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1833\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'NAmes':12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1834\n",
    "x=error_cols[2]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1835\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Duplex':2,'Twnhs':0,'2fmCon':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1836\n",
    "x=error_cols[3]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1837\n",
    "x=error_cols[4]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1838\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Wd_Sdng':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1839\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Wd Sdng':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1840\n",
    "x=error_cols[5]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1841\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'Wd Sdng':1,'CmentBd':11, 'Wd Shng':0,'Brk Cmn':14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1842\n",
    "x=error_cols[6]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1843\n",
    "x=error_cols[7]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1844\n",
    "x=error_cols[8]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1845\n",
    "GarageYrBlt has instances of NA---FIX\n",
    "Functional has int values but shows dytpe of object for some reason\n",
    "KitchenQual has in values but shows dtype of object for some reason\n",
    "ExterQual \"\"\n",
    "Exter2nd(5) has uncoverted instances\n",
    "Exter1st has uncoverted instances\n",
    "'Bldgtype' \"\"\n",
    "Neighborhood \"\" 'NAmes'\n",
    "MSZoning \"\"  'C (all)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the misspelled variable names\n",
    "scale_mapper= {'NA':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)\n",
    "train[x].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1846\n",
    "x=error_cols[9]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1847\n",
    "x=error_cols[10]\n",
    "xtest[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1848\n",
    "#Test to make sure that that the encoding worked\n",
    "temp=pd.read_csv(\"./train.csv\")\n",
    "x='Functional'\n",
    "temp[x].value_counts(),train[x].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1849\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1850\n",
    "xtest['Condition2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1851\n",
    "fig = sns.boxplot(y='SalePrice', x=\"MSSubClass\", data=train)\n",
    "#MSsubclass is not ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1852\n",
    "remove ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[train.columns[1:80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1853\n",
    "x='MoSold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {12: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1854\n",
    "Bin Months(seasons) 12,1,2  3,4,5 6,7,8 9,10,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf=pd.DataFrame()\n",
    "bins=[-1,2,6,8,11]\n",
    "arf=pd.cut(train[x],bins,labels=[0,1,2,3]).astype('int64')\n",
    "train[x]=arf\n",
    "xtest[x]=pd.cut(xtest[x],bins,labels=[0,1,2,3]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='MoSold'\n",
    "data=train[['SalePrice', x]]\n",
    "data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 1855\n",
    "#Replace yr sold with num values 2006: 0,2007:1,2008:2,2009:3, 2010:4\n",
    "# will need to one hot encode for regression\n",
    "x='YrSold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r=pd.read_csv(\"./train.csv\")\n",
    "ra=pd.read_csv(\"./test.csv\")\n",
    "train[x]=r[x]\n",
    "xtest[x]=ra[x]\n",
    "xtest[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_mapper= {2006: 0,2007:1,2008:2,2009:3, 2010:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].replace(scale_mapper)\n",
    "xtest[x]=xtest[x].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrLiv_data=train[['SalePrice', x]]\n",
    "GrLiv_data.plot.scatter(x, y='SalePrice',ylim=(0,800000));\n",
    "plt.xlabel(x,fontsize=12)\n",
    "plt.ylabel('SalePrice',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1856\n",
    "train.info()\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1857\n",
    "train.info()\n",
    "#xtest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1858\n",
    "Change rest of the objects into int64, Now everything is numerically encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['MiscFeature','GarageQual','Heating','BsmtCond','RoofMatl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[x]=train[x].astype('int64')\n",
    "xtest[x]=xtest[x].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1859\n",
    "train.info()\n",
    "xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1860\n",
    "train.info()\n",
    "#xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1861\n",
    "xtrain=train[train.columns[1:80]]\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1862\n",
    "#train_mod and xtest_mod \n",
    "train.to_csv('train_v1.csv',index=False)\n",
    "xtest.to_csv('test_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1863\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=60, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1864\n",
    "np.mean(cvscores),cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1865\n",
    "#Train parity\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1866\n",
    "#Test parity\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1867\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], ytrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1868\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1869\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1870\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in xtrain.columns if col not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1871\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in xtrain.columns if col not in catcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1872\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in xtrain.columns if col not in catcols]\n",
    "intcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1873\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in xtrain.columns if col not in catcols]\n",
    "nomcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1874\n",
    "cat=pd.read_csv(\"./categorical.csv\")\n",
    "catcols=cat['categories'].unique().tolist()\n",
    "hotcols=cat[cat['encode']=='hot']['categories'].tolist()\n",
    "nomcols=cat[cat['encode']=='nom']['categories'].tolist()\n",
    "intcols = [col for col in xtrain.columns if col not in catcols]\n",
    "intcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1875\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xtrain[intcols])\n",
    "ttrain=scaler.transform(xtrain[intcols])\n",
    "ttest=scaler.transform(xtest[intcols])\n",
    "xtest[intcols]=pd.DataFrame(ttest, columns=intcols)\n",
    "xtrain[intcols]=pd.DataFrame(ttrain, columns=intcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1876\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1877\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1878\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1879\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1880\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=60, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=100)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1881\n",
    "np.mean(cvscores),cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1882\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1883\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1884\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], ytrain)\n",
    "y_pred=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1885\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1886\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1887\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1888\n",
    "#Test parity\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1889\n",
    "#Train parity\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1890\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "yltrain=(np.log(ytrain))\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 60],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2,3,8],\n",
    "    'n_estimators': [100, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf,param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(xtrain[topcols], yltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1891\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "#xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1892\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1893\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1894\n",
    "xtrain.to_csv('xtrain_sscale.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale.csv',index=False)\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1895\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1896\n",
    "#Test parity\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1897\n",
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    regr = RandomForestRegressor(max_depth=30, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    print('For cross validation set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_test, y_pred))\n",
    "    \n",
    "    print('For Training set')\n",
    "    print('Root mean squared error: %.2f'\n",
    "          % np.sqrt(mean_squared_error((y_train), (y_predtr))))\n",
    "    \n",
    "    print('Coefficient of determination: %.2f'\n",
    "          % r2_score(y_train, y_predtr)) \n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1898\n",
    "np.mean(cvscores),cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1899\n",
    "#Test parity\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "x=[0,700000]\n",
    "y=x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1900\n",
    "#Train parity\n",
    "x=[10.5,14]\n",
    "y=x\n",
    "plt.scatter((y_train),(y_predtr))\n",
    "plt.xlabel('y_test')\n",
    "plt.xlabel('y_pred')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1901\n",
    "regr = RandomForestRegressor(max_depth=20, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "ytest=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1902\n",
    "regr = RandomForestRegressor(max_depth=30, max_features= 5,min_samples_split=2, min_samples_leaf=3, random_state=0, n_estimators=300)\n",
    "regr.fit(xtrain[topcols], yltrain)\n",
    "ytest=regr.predict(xtest[topcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1903\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=ytest\n",
    "ans.to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1904\n",
    "One hot encoded AND num coded train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "xtest.drop(hotcols, axis=1, inplace=True)\n",
    "xtest=pd.concat([xtest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1905\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1906\n",
    "One hot encoded AND num coded train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(xtest[hotcols].astype(str))\n",
    "xtest.drop(hotcols, axis=1, inplace=True)\n",
    "xtest=pd.concat([xtest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1907\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1908\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1909\n",
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1910\n",
    "xtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1911\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1912\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('xtrain_sscale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1913\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1914\n",
    "get_ipython().system('ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('xtrain_sscale.csv')\n",
    "test=pd.read_csv('xtest_sscale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1915\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1916\n",
    "test[numcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1917\n",
    "test[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1918\n",
    "train[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1919\n",
    "train[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1920\n",
    "test[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1921\n",
    "tar=test.drop(hotcols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1922\n",
    "test[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1923\n",
    "tar=test.drop(hotcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1924\n",
    "tar=test.drop(hotcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1925\n",
    "tar=test.drop(hotcols,axis=1)\n",
    "tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1926\n",
    "tar=test.drop(hotcols,axis=1)\n",
    "tar\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1927\n",
    "tar=test.drop(hotcols,axis=1)\n",
    "tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1928\n",
    "One hot encoded AND num coded train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(test[hotcols].astype(str))\n",
    "#temptest=test.drop(hotcols, axis=1)\n",
    "#fintest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hottrain=pd.get_dummies(xtrain[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "#xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Cell 1929\n",
    "One hot encoded AND num coded train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hottest=pd.get_dummies(test[hotcols].astype(str))\n",
    "#temptest=test.drop(hotcols, axis=1)\n",
    "#fintest=pd.concat([temptest, hottest],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hottrain=pd.get_dummies(train[hotcols].astype(str))\n",
    "#xtrain.drop(hotcols, axis=1, inplace=True)\n",
    "#xtrain=pd.concat([xtrain,hottrain],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1930\n",
    "hottest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1931\n",
    "hottest.shape[0]\n",
    "hottrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1932\n",
    "hottest.shape[],hottrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1933\n",
    "hottest.shape,hottrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1934\n",
    "hottest.shape,hottrain.shape\n",
    "test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1935\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1936\n",
    "hottest.shape #,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1937\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1938\n",
    "train[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1939\n",
    "train[hotcols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1940\n",
    "hottest=train[hotcols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1941\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1942\n",
    "hottest=train[hotcols].astype(str)\n",
    "hottrain=(train[hotcols].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1943\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1944\n",
    "hottest=get_dummies(train[hotcols[0]].astype(str))\n",
    "hottrain=(train[hotcols[0]].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1945\n",
    "hottest=pd.get_dummies(train[hotcols[0]].astype(str))\n",
    "hottrain=pd.get_dummies(train[hotcols[0]].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1946\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1947\n",
    "hottest=pd.get_dummies(train[hotcols[1]].astype(str))\n",
    "hottrain=pd.get_dummies(train[hotcols[1]].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1948\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1949\n",
    "hottest=pd.get_dummies(train[hotcols[2]].astype(str))\n",
    "hottrain=pd.get_dummies(train[hotcols[2]].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1950\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1951\n",
    "hottest=pd.get_dummies(train[hotcols[3]].astype(str))\n",
    "hottrain=pd.get_dummies(train[hotcols[3]].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1952\n",
    "hottest.shape,hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1953\n",
    "hottest.shape==hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1954\n",
    "hottest.shape!=hottrain.shape\n",
    "#test.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1955\n",
    "hotcols.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1956\n",
    "len(hotcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1957\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    if hottest.shape!=hottrain.shape\n",
    "        print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1958\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    if hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1959\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    \n",
    "    if hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    elif hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1960\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    \n",
    "    if hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    elif hottest.shape==hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1961\n",
    "tot=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    tot=hottest.shape[i]+tot\n",
    "    if hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    elif hottest.shape==hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1962\n",
    "tot=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    tot=hottest.shape[1]+tot\n",
    "    if hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    elif hottest.shape==hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1963\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1964\n",
    "hottest=pd.get_dummies(train[hotcols].astype(str))\n",
    "hottest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1965\n",
    "hottest=pd.get_dummies(test[hotcols].astype(str))\n",
    "hottest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1966\n",
    "tot=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    tot=hottest.shape[1]+tot\n",
    "    if hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    elif hottest.shape==hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1967\n",
    "tot=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    tot=hottest.shape[1]+tot\n",
    "    if hottest.shape!=hottrain.shape:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1968\n",
    "tot=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    tot=hottest.shape[1]+tot\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1969\n",
    "tot=0\n",
    "tottrain=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1970\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1971\n",
    "tottrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1972\n",
    "pd.concat[test,train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1973\n",
    "pd.concat(test,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1974\n",
    "pd.concat([test,train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1975\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1976\n",
    "pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1977\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1978\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1979\n",
    "train.shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1980\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1981\n",
    "tot=0\n",
    "tottrain=0\n",
    "totcomp=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    comp=pd.concat([train,test]).astype(str)\n",
    "    hotcomp=pd.get_dummies(comp)\n",
    "    \n",
    "    totcomp=comp.shape[1]=totcomp\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1982\n",
    "tot=0\n",
    "tottrain=0\n",
    "totcomp=0\n",
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    comp=pd.concat([train,test]).astype(str)\n",
    "    hotcomp=pd.get_dummies(comp)\n",
    "    \n",
    "    totcomp=comp.shape[1]+totcomp\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1983\n",
    "pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1984\n",
    "pd.concat([train[hotcols[i]],test[hotcols[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1985\n",
    "tot=0\n",
    "tottrain=0\n",
    "totcomp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    comp=pd.concat([train[hotcols[i],test[hotcols[i]]]).astype(str)\n",
    "    hotcomp=pd.get_dummies(comp)\n",
    "    \n",
    "    \n",
    "    totcomp=comp.shape[1]+totcomp\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1986\n",
    "tot=0\n",
    "tottrain=0\n",
    "totcomp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    comp=pd.concat([train[hotcols[i],test[hotcols[i]]]]).astype(str)\n",
    "    hotcomp=pd.get_dummies(comp)\n",
    "    \n",
    "    \n",
    "    totcomp=comp.shape[1]+totcomp\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1987\n",
    "pd.concat([train[hotcols[0]],test[hotcols[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1988\n",
    "pd.concat([train[hotcols[0]],test[hotcols[0]]]).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1989\n",
    "tot=0\n",
    "tottrain=0\n",
    "totcomp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    comp=pd.concat([train[hotcols[i]],test[hotcols[i]]]).astype('int')\n",
    "    hotcomp=pd.get_dummies(comp)\n",
    "    \n",
    "    \n",
    "    totcomp=comp.shape[1]+totcomp\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1990\n",
    "comp.sahpe[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1991\n",
    "comp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1992\n",
    "comp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1993\n",
    "hottrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1994\n",
    "hotcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1995\n",
    "tot=0\n",
    "tottrain=0\n",
    "totcomp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    comp=pd.concat([train[hotcols[i]],test[hotcols[i]]]).astype('int')\n",
    "    hotcomp=pd.get_dummies(comp)\n",
    "    \n",
    "    \n",
    "    totcomp=hotcomp.shape[1]+totcomp\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1996\n",
    "hotcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1997\n",
    "totcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1998\n",
    "totcomp, tottrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 1999\n",
    "totcomp, tottrain,tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2000\n",
    "comp=pd.concat([train[hotcols,test[hotcols]).astype('int')\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2001\n",
    "comp=pd.concat([train[hotcols,test[hotcols]]).astype('int')\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2002\n",
    "comp=pd.concat([train[hotcols,test[hotcols]]]).astype('int')\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2003\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype('int')\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2004\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype('int')\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotcomp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2005\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype('int')\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2006\n",
    "tot=0\n",
    "tottrain=0\n",
    "totcomp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hotcols)):\n",
    "    hottest=pd.get_dummies(test[hotcols[i]].astype(str))\n",
    "    hottrain=pd.get_dummies(train[hotcols[i]].astype(str))\n",
    "    comp=pd.concat([train[hotcols[i]],test[hotcols[i]]]).astype(str)\n",
    "    hotcomp=pd.get_dummies(comp)\n",
    "    \n",
    "    \n",
    "    totcomp=hotcomp.shape[1]+totcomp\n",
    "    tot=hottest.shape[1]+tot\n",
    "    tottrain=hottrain.shape[1]+tottrain\n",
    "    if hottest.shape[1]!=hottrain.shape[1]:\n",
    "        print(hottest.shape,hottrain.shape,i)\n",
    "    #elif hottest.shape==hottrain.shape:\n",
    "     #   print(hottest.shape,hottrain.shape,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2007\n",
    "totcomp, tottrain,tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2008\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotcomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2009\n",
    "xtrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2010\n",
    "hotcomp.loc[:1460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2011\n",
    "hotcomp.iloc[:1460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2012\n",
    "hotcomp.iloc[:1460].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2013\n",
    "hotcomp.iloc[:1460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2014\n",
    "xtest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2015\n",
    "hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2016\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_hot=hotcomp.iloc[:1460]\n",
    "xtest_hot=hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2017\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_hot=hotcomp.iloc[:1460]\n",
    "xtest_hot=hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2018\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_hot=hotcomp.iloc[:1460]\n",
    "xtest_hot=hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=pd.concat([train,xtest_hot],axis=1)\n",
    "temptest=pd.concat([test,xtest_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2019\n",
    "temptrain.shape,temptest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2020\n",
    "temptrain=temptrain.drop(hotcols,axis=1)\n",
    "temptrain=temptest.drop(hotcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2021\n",
    "temptrain.shape,temptest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2022\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_hot=hotcomp.iloc[:1460]\n",
    "xtest_hot=hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=pd.concat([train,xtest_hot],axis=1)\n",
    "temptest=pd.concat([test,xtest_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2023\n",
    "temptrain.shape,temptest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2024\n",
    "temptrain=temptrain.drop(hotcols,axis=1)\n",
    "temptrain=temptest.drop(hotcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2025\n",
    "temptrain.shape,temptest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2026\n",
    "temptrain=temptrain.drop(hotcols,axis=1)\n",
    "temptest=temptest.drop(hotcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2027\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_hot=hotcomp.iloc[:1460]\n",
    "xtest_hot=hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=pd.concat([train,xtest_hot],axis=1)\n",
    "temptest=pd.concat([test,xtest_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2028\n",
    "temptrain=temptrain.drop(hotcols,axis=1)\n",
    "temptest=temptest.drop(hotcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2029\n",
    "temptrain.shape,temptest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2030\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_hot=hotcomp.iloc[:1460]\n",
    "xtest_hot=hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=pd.concat([train,xtest_hot],axis=1)\n",
    "temptest=pd.concat([test,xtest_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=temptrain.drop(hotcols,axis=1)\n",
    "temptest=temptest.drop(hotcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=temptrain\n",
    "xtest=temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2031\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2032\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2033\n",
    "xtest[hotcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2034\n",
    "xtest[numcols[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2035\n",
    "xtest[numcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2036\n",
    "xtest[nomcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2037\n",
    "xtest[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2038\n",
    "xtrain[intcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2039\n",
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2040\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2041\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2042\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2043\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2044\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2045\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2046\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5,).fit(X, y)\n",
    "clf.score(X, y)\n",
    "alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2047\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5,).fit(X, y)\n",
    "clf.score(X, y)\n",
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2048\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5,).fit(X, y)\n",
    "clf.score(X, y)\n",
    "clf.cv_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2049\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5,).fit(X, y)\n",
    "clf.score(X, y)\n",
    "clf.cv_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2050\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5,store_cv_values=True).fit(X, y)\n",
    "clf.score(X, y)\n",
    "clf.cv_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2051\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5,store_cv_values=False).fit(X, y)\n",
    "clf.score(X, y)\n",
    "clf.cv_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2052\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X, y)\n",
    "clf.cv_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2053\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2054\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2055\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2056\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2057\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2058\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2059\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2060\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2061\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2062\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2063\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2064\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2065\n",
    "comp.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2066\n",
    "comp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2067\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2068\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2069\n",
    "xtrain_hot=hotcomp.iloc[:1460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2070\n",
    "xtrain_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2071\n",
    "hotcomp.iloc[1460:1461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2072\n",
    "hotcomp.iloc[1460:1462]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2073\n",
    "hotcomp.iloc[1460:1463]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2074\n",
    "hotcomp.iloc[1460:1464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2075\n",
    "comp=pd.concat([train[hotcols],test[hotcols]]).astype(str)\n",
    "hotcomp=pd.get_dummies(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "xtrain_hot=hotcomp.iloc[:1460]\n",
    "xtest_hot=hotcomp.iloc[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=pd.concat([train,xtrain_hot],axis=1)\n",
    "temptest=pd.concat([test,xtest_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temptrain=temptrain.drop(hotcols,axis=1)\n",
    "temptest=temptest.drop(hotcols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=temptrain\n",
    "xtest=temptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.to_csv('xtrain_sscale_hot.csv',index=False)\n",
    "xtest.to_csv('xtest_sscale_hot.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2076\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2077\n",
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2078\n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2079\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2080\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2081\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2082\n",
    "clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2083\n",
    "ytest=clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2084\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2085\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2086\n",
    "train=pd.read_csv(\"./train.csv\")\n",
    "test=pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2087\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=ytest\n",
    "ans.to_csv('data_ridge.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2088\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2089\n",
    "yrg=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2090\n",
    "plt.scatter(yrg,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2091\n",
    "yrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2092\n",
    "plt.scatter(yrg['SalePrice'],ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2093\n",
    "plt.scatter(yrg['SalePrice'],ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2094\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    ridge = Ridge(alpha=1)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred=regr.predict(X_test)\n",
    "    y_predtr=regr.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2095\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2096\n",
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2097\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2098\n",
    "plt.scatter(y_train,y_predtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2099\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2100\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2101\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2102\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,5],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2103\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,10],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2104\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,5],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2105\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,2],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2106\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,1],cv=5).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2107\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,1],cv=None,store_cv_values=True).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2108\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,1],cv=None,store_cv_values=True).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2109\n",
    "from sklearn.linear_model import RidgeCV\n",
    "X = xtrain\n",
    "y = np.log(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1,1],cv=None,store_cv_values=True).fit(X, y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2110\n",
    "clf.cv_values_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2111\n",
    "np.mean(clf.cv_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2112\n",
    "np.mean(clf.cv_values_,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2113\n",
    "np.mean(clf.cv_values_,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2114\n",
    "np.mean(clf.cv_values_,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2115\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=2)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2116\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2117\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=.001)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2118\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2119\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2120\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2121\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1.5)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2122\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2123\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=2)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2124\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2125\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=3)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2126\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2127\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=2)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2128\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2129\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2130\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2131\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=40)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2132\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2133\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2134\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2135\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2136\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2137\n",
    "plt.scatter(np.exp(y_test),np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2138\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols].iloc[train_index], xtrain[topcols].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2139\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2140\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2141\n",
    "cvscores.mean(,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2142\n",
    "cvscores.mean(),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2143\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2144\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2145\n",
    "np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2146\n",
    "np.exp(y_pred)>50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2147\n",
    "np.exp(y_pred)>1750000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2148\n",
    "np.argwhere(np.exp(y_pred)>1750000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2149\n",
    "np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2150\n",
    "np.exp(y_pred).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2151\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2152\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=.5)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2153\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2154\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2155\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2156\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=0)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2157\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2158\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=.001)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2159\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2160\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2161\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2162\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=0)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2163\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2164\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2165\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2166\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=0.01)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2167\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2168\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2169\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2170\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2171\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2172\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=2)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2173\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2174\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2175\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=3)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2176\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2177\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=50000)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2178\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2179\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=5)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2180\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2181\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=6)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2182\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2183\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2184\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2185\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=100)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2186\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2187\n",
    "mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2188\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2189\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1000)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2190\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2191\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=100)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2192\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2193\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=50)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2194\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2195\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=40)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2196\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2197\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=20)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2198\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2199\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2200\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2201\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=20)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2202\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2203\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=30)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2204\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2205\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=40)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2206\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2207\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=30)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2208\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2209\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=30)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2210\n",
    "np.mean(cvscores),trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2211\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2212\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2213\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2214\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=20)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2215\n",
    "cvscores,trscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2216\n",
    "cvscores,trscores,cvscores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2217\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2218\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2219\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2220\n",
    "rid.fit(xtrain,ytrain)\n",
    "rid.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2221\n",
    "rid.fit(xtrain,ytrain)\n",
    "ypred=rid.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2222\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=np.exp(ytest)\n",
    "ans.to_csv('data_ridge.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2223\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=np.exp(ypred)\n",
    "ans.to_csv('data_ridge.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2224\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=np.exp(ypred)\n",
    "ans.to_csv('data_ridg.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2225\n",
    "plt.plot(np.exp(yrg['Saleprice']),np.exp(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2226\n",
    "plt.plot(np.exp(yrg['SalePrice']),np.exp(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2227\n",
    "yrg['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2228\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2229\n",
    "plt.plot(np.exp(yrg['SalePrice']),ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2230\n",
    "plt.scatter(np.exp(yrg['SalePrice']),ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2231\n",
    "x=[0,60000]\n",
    "y=[0,60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2232\n",
    "plt.scatter(np.exp(yrg['SalePrice']),ypred)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2233\n",
    "x=[0,600000]\n",
    "y=[0,600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2234\n",
    "plt.scatter(np.exp(yrg['SalePrice']),ypred)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2235\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2236\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2237\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2238\n",
    "np.exp(y_train)-np.exp(y_predtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2239\n",
    "plt.scatter(np.exp(y_train),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2240\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=20)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2241\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2242\n",
    "plt.scatter((y_train),(y_train)-(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2243\n",
    "#Clearly nonlinear!\n",
    "plt.scatter((y_train),(y_train)-(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2244\n",
    "#Clearly nonlinear!\n",
    "#Use log transform on skewed y variable\n",
    "plt.scatter((y_predtr),(y_train)-(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2245\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=20)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2246\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2247\n",
    "plt.scatter(np.exp(y_predtr),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2248\n",
    "xtrain.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2249\n",
    "ytrain.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2250\n",
    "xtrain.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2251\n",
    "ytrain.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2252\n",
    "np.log(ytrain).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2253\n",
    "np.log(xtrain).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2254\n",
    "(xtrain).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2255\n",
    "(xtrain).skew()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2256\n",
    "(xtrain).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2257\n",
    "(xtrain).skew().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2258\n",
    "np.abs((xtrain).skew()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2259\n",
    "np.abs((xtrain).skew()).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2260\n",
    "np.abs((xtrain).skew()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2261\n",
    "np.abs((xtrain).skew()).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2262\n",
    "np.abs((xtrain).skew()).sort_values(ascending=False)[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2263\n",
    "np.abs((xtrain).skew()).sort_values(ascending=False)[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2264\n",
    "np.abs((xtrain).skew()).sort_values(ascending=False)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2265\n",
    "np.abs((xtrain).skew()).sort_values(ascending=False)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2266\n",
    "np.abs((xtrain).skew()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2267\n",
    "np.abs((xtrain[intcols]).skew()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2268\n",
    "xtrain['MiscVal'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2269\n",
    "xtrain['PoolArea'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2270\n",
    "xtrain['LotArea'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2271\n",
    "xtrain['LotArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2272\n",
    "xtrain['BsmtFinSF2'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2273\n",
    "xtrain['MasVnrArea'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2274\n",
    "np.log(xtrain['MasVnrArea']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2275\n",
    "np.log(1+xtrain['MasVnrArea']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2276\n",
    "np.log(xtrain['MasVnrArea']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2277\n",
    "xtrain['MasVnrArea']**1/3.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2278\n",
    "xtrain['MasVnrArea']**(1/3).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2279\n",
    "np.log(xtrain['MasVnrArea']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2280\n",
    "np.power(xtrain['MasVnrArea'],1/3).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2281\n",
    "np.power(xtrain['MasVnrArea'],1/4).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2282\n",
    "xtrain[topcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2283\n",
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2284\n",
    "xtrain.str.contains('MoSold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2285\n",
    "print(xtrain.filter(like='MoSold').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2286\n",
    "print(xtrain.filter(like='MsZoning').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2287\n",
    "print(xtrain.filter(like='MSZoning').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2288\n",
    "print(xtrain.filter(like='Foundation').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2289\n",
    "print(xtrain.filter(like='CentralAir').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2290\n",
    "topcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2291\n",
    "topcols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2292\n",
    "topcols[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2293\n",
    "len(topcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2294\n",
    "topcols[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2295\n",
    "topcols[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2296\n",
    "topcols[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2297\n",
    "topcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2298\n",
    "topcols[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2299\n",
    "topcols[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2300\n",
    "topcols[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2301\n",
    "topcols[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2302\n",
    "topcols[0:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2303\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols[0:23]].iloc[train_index], xtrain[topcols[0:23]].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=20)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2304\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2305\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols[0:23]].iloc[train_index], xtrain[topcols[0:23]].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2306\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2307\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols[0:23]].iloc[train_index], xtrain[topcols[0:23]].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2308\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2309\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols[0:23]].iloc[train_index], xtrain[topcols[0:23]].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2310\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2311\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols[0:23]].iloc[train_index], xtrain[topcols[0:23]].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2312\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2313\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols[0:23]].iloc[train_index], xtrain[topcols[0:23]].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=100)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2314\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2315\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain[topcols[0:23]].iloc[train_index], xtrain[topcols[0:23]].iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=15)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2316\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2317\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=15)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2318\n",
    "cvscores,trscores,np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2319\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvcores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2320\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2321\n",
    "np.exp(.138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2322\n",
    "np.expn(.138**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2323\n",
    "np.exp(.138**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2324\n",
    "np.mean((y_train)-(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2325\n",
    "np.std((y_train)-(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2326\n",
    "plt.scatter(np.exp(y_train),np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2327\n",
    "#Clearly nonlinear!\n",
    "#Use log transform on skewed y variable\n",
    "plt.scatter((y_predtr),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2328\n",
    "#Clearly nonlinear!\n",
    "#Use log transform on skewed y variable\n",
    "plt.scatter((y_predtr),(y_train)-(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2329\n",
    "#Clearly nonlinear!\n",
    "#Use log transform on skewed y variable\n",
    "plt.scatter((y_predtr),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2330\n",
    "plt.scatter(np.exp(y_predtr),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2331\n",
    "np.exp(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2332\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2333\n",
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2334\n",
    "ytrain.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2335\n",
    "#Clearly nonlinear!\n",
    "#Use log transform on skewed y variable\n",
    "plt.scatter(np.exp(y_predtr),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2336\n",
    "np.std(np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2337\n",
    "plt.scatter((y_test),(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2338\n",
    "plt.scatter((y_test),(y_pred))\n",
    "np.std(np.exp(y_test)-np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2339\n",
    "plt.scatter((y_test),(y_pred))\n",
    "plt.scatter(np.exp(y_pred),np.exp(y_test)-np.exp(y_pred))\n",
    "np.std(np.exp(y_test)-np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2340\n",
    "#plt.scatter((y_test),(y_pred))\n",
    "plt.scatter(np.exp(y_pred),np.exp(y_test)-np.exp(y_pred))\n",
    "np.std(np.exp(y_test)-np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2341\n",
    "plt.scatter((y_test),(y_pred))\n",
    "#plt.scatter(np.exp(y_pred),np.exp(y_test)-np.exp(y_pred))\n",
    "#np.std(np.exp(y_test)-np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2342\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=((ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=15)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2343\n",
    "#Clearly nonlinear!\n",
    "#Use log transform on skewed y variable\n",
    "plt.scatter(np.exp(y_predtr),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2344\n",
    "#Clearly nonlinear!\n",
    "#Use log transform on skewed y variable\n",
    "plt.scatter((y_predtr),(y_train)-(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2345\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=15)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2346\n",
    "plt.scatter(np.exp(y_predtr),np.exp(y_train)-np.exp(y_predtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2347\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2348\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2349\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2350\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=100)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2351\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2352\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2353\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2354\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=5)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2355\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2356\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=1)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2357\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2358\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2359\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2360\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=20)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2361\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2362\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=50)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2363\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2364\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cvscores=[]\n",
    "trscores=[]\n",
    "yltrain=(np.log(ytrain))\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    X_train, X_test = xtrain.iloc[train_index], xtrain.iloc[test_index]\n",
    "    y_train, y_test = yltrain.iloc[train_index], yltrain.iloc[test_index]\n",
    "    rid = Ridge(alpha=10)\n",
    "    rid.fit(X_train, y_train)\n",
    "    y_pred=rid.predict(X_test)\n",
    "    y_predtr=rid.predict(X_train)\n",
    "    \n",
    "    cvscores.append(np.sqrt(mean_squared_error((y_test), (y_pred))))\n",
    "    \n",
    "    trscores.append(np.sqrt(mean_squared_error((y_train), (y_predtr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2365\n",
    "cvscores,trscores,np.mean(cvscores),np.std(cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2366\n",
    "rid.fit(xtrain,ytrain)\n",
    "ypred=rid.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2367\n",
    "ans=pd.DataFrame()\n",
    "ans['Id']=test['Id']\n",
    "ans['SalePrice']=np.exp(ypred)\n",
    "ans.to_csv('data_ridge.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2368\n",
    "plt.scatter((ytest),(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2369\n",
    "rid.fit(xtrain,np.log(ytrain))\n",
    "ypred=rid.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2370\n",
    "plt.scatter((np.log(ytest),(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2371\n",
    "plt.scatter(np.log(ytest),(ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2372\n",
    "rid.fit(xtrain,np.log(ytrain))\n",
    "ytrainpred=rid.predict(xtrain)\n",
    "ypred=rid.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2373\n",
    "plt.scatter(np.log(ytest),(ytrainpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2374\n",
    "ytrain.shape,ytrainpred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2375\n",
    "plt.scatter(ytrain,ytrainpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@ Cell 2376\n",
    "plt.scatter(np.log(ytrain),ytrainpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# @@ Cell 2377\n",
    "ypred"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
